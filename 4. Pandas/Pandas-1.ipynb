{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Analysis in Python: Introduction to Pandas\n",
    "\n",
    "Pandas is built on top of numPy, and is designed to eliminate the need for writing loops for any filtering or aggregation work. It is implemented in C, so is around 15x faster than base python.\n",
    "\n",
    "Key Features\n",
    "* Easy handling of ***missing data.*** (`dropna, fillna, ffill, isnull, notnull`)\n",
    "* Simple ***mutations*** of tables (add/remove columns)\n",
    "* Easy ***slicing*** of data (fancy indexing and subsetting)\n",
    "* Automatic ***data alignment*** (by index)\n",
    "* Powerful ***split-apply-combine*** (`groupby`)\n",
    "* Intuitive ***merge/join*** (`concat, join`)\n",
    "* Reshaping and ***Pivoting*** (`stack, pivot`)\n",
    "* ***Hierarchical Labeling*** of axes indices\n",
    "* Robust ***I/O tools*** to work with csv, Excel, flat files, ***databases and HDFS***\n",
    "* Integrated ***Time Series*** Functionality\n",
    "* Easy plotting (`plot`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stack Overflow page for handling big data workflows in Pandas [link](http://stackoverflow.com/questions/14262433/large-data-work-flows-using-pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the `array()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_1d = np.array((1, 2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_1d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_2d = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]); arr_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_3d = array([arr_2d, arr_2d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_3d.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Using generation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(16).reshape(4, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_1d = np.random.randint(1, 100, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_2d = np.random.randint(0, 1000, 16).reshape(4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randn(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randn(30).reshape(5, 6).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting (get a number or many numbers from an array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_1d[::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting a single number\n",
    "arr_2d[3, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_2d[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_2d[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_2d[:2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_2d[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_2d[2:4, 2:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting with Booleans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_1d > 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_1d[arr_1d > 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_2d % 2 == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_2d[arr_2d % 2 == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathematical Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print arr_1d\n",
    "arr_1d + arr_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print arr_2d\n",
    "arr_2d + arr_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Math Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(arr_1d).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(arr_2d).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Array Attribues and Methods\n",
    "\n",
    "- commonly used: `reshape, round... `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array([True, True, False, True]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array([True, True, False, True]).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_1d.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_1d.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_1d[arr_1d.argsort()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_1d.clip(20, 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Pandas\n",
    "\n",
    "http://pandas.pydata.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "- A fast and efficient DataFrame object for data manipulation with integrated indexing;\n",
    "- Tools for reading and writing data between in-memory data structures and different formats: CSV and text files, Microsoft Excel, SQL databases, and the fast HDF5 format;\n",
    "- Intelligent data alignment and integrated handling of missing data: gain automatic label-based alignment in computations and easily manipulate messy data into an orderly form;\n",
    "- Flexible reshaping and pivoting of data sets;\n",
    "- Intelligent label-based slicing, fancy indexing, and subsetting of large data sets;\n",
    "- Columns can be inserted and deleted from data structures for size mutability;\n",
    "- Aggregating or transforming data with a powerful group by engine allowing split-apply-combine operations on data sets;\n",
    "- High performance merging and joining of data sets;\n",
    "- Hierarchical axis indexing provides an intuitive way of working with high-dimensional data in a lower-dimensional data structure;\n",
    "- Time series-functionality: date range generation and frequency conversion, moving window statistics, moving window linear regressions, date shifting and lagging. Even create domain-specific time offsets and join time series without losing data;\n",
    "- Highly optimized for performance, with critical code paths written in Cython or C.\n",
    "- Python with pandas is in use in a wide variety of academic and commercial domains, including Finance, Neuroscience, Economics, Statistics, Advertising, Web Analytics, and more.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import Series, DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Importing a CSV File\n",
    "\n",
    "Reading a CSV is as simple as calling the read_csv function. By default, the `read_csv` function expects the column separator to be a comma, but you can change that using the sep parameter.\n",
    "\n",
    "Syntax: `pd.read_csv(filepath, sep=, header=, names=, skiprows=, na_values= ... )`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect file without importing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc -l train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -10 train.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Support for SQL Databases\n",
    "\n",
    "pandas also has some support for reading/writing DataFrames directly from/to a database. \n",
    "\n",
    "You'll typically just need to pass a connection object to the `read_frame` or `write_frame` functions within the pandas.io module.\n",
    "\n",
    "***Note*** `write_frame` executes as a series of `INSERT INTO` statements and thus trades speed for simplicity. If you're writing a large DataFrame to a database, it might be quicker to write the DataFrame to CSV and load that directly using the database's file import arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in os.listdir(os.getcwd()) if 'db' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.read_sql?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.io import sql\n",
    "import sqlite3 \n",
    "\n",
    "conn = sqlite3.connect('towed.db')\n",
    "query = \"SELECT * FROM towed WHERE make = 'FORD';\"\n",
    "\n",
    "results = pd.read_sql(query, con=conn)\n",
    "print results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql(\"SELECT distinct make, count(*) from towed group by 1 order by 2 desc limit 10\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Read: \n",
    "\n",
    "1. Homepage http://www.sqlalchemy.org/\n",
    "2. Engines http://docs.sqlalchemy.org/en/latest/core/engines.html\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Reading from the Clipboard!\n",
    "\n",
    "This is as straight forward as it ought to be.\n",
    "\n",
    "Example: `df_2 = pd.read_clipboard(); df_2.head()`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---\n",
    "## 1. Series\n",
    "It is a 1-d array of data (similar to an array/list/column in a table) with an associated **labeled _index_.**\n",
    "\n",
    " It can be created in the same way as a NumPy array is created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Syntax: `Series(data=, index=, dtype=, name=)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import Series, DataFrame, read_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_random = np.random.randn(10).round(2)\n",
    "\n",
    "print type(x_random)\n",
    "x_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Series(x_random, \n",
    "       name='my_series_1', \n",
    "       dtype=object, \n",
    "       index=['ind_' + str(i) for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_random = Series(x_random)\n",
    "# no index specified, numeric will be automatically generated\n",
    "print type(s_random)\n",
    "s_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series = Series(x_random, index=list('aabbbccdef'))\n",
    "# passing an index specifically\n",
    "my_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<big>\n",
    "- Using a list, tuple or dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_1 = {v: k for k, v in zip(np.random.random(10).round(2), list('abcdefghij'))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Series(dict_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Series(data=[1, 2, 3], \n",
    "       index=list('abc'), \n",
    "       name='Series_1', \n",
    "       dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Series(data=(1, 2, 3), index=list('abc'), \n",
    "       name='Series_1', dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Series({'a': 1, 'b': 2, 'c':3}, dtype=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Series Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(my_series.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying the Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_series.index = list('abcde' * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_series.name = 'ser1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- Convert a dictonary to a Series, using the **keys** of the dictionary as its **index**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Task 1:** Declare a series using this data, \n",
    "```\n",
    "{'ham': 1, 'eggs': 3, 'bacon': 2, 'coffee': 1, 'toast': 0.5, 'jam': 0.2}\n",
    "```\n",
    "- The menu options should form the index.\n",
    "- The series should be called 'menu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diner = Series({'ham': 1, 'eggs': 3, 'bacon': 2, 'coffee': 1, 'toast': 0.5, 'jam': 0.2},\n",
    "              name='menu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Diner = diner.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{k:Diner[k] for k in ['eggs', 'bacon']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Diner[['eggs', 'bacon']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diner[['eggs', 'bacon']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diner['coffee':'jam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diner + 0.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diner.map(lambda x: float(x) + 0.50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Subsetting a Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<big>\n",
    "\n",
    "The different methods of subsetting that we've seen so far include\n",
    "\n",
    "- Using slices or positional indexers (for lists and arrays)\n",
    "- Using keys (for dictionaries)\n",
    "- Using bools (for arrays)\n",
    "\n",
    "For the Pandas Series, we can use either of the above strategies, leveraging specialized methods for pulling data from a Series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series = Series(np.random.randn(5).round(2), index = list('abcde'))\n",
    "my_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Label\n",
    "my_series['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of Labels\n",
    "my_series[['a', 'b']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Slice\n",
    "my_series['b':'d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positional slicing\n",
    "my_series[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series[::-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_2 = Series(list('abcde'), index=range(1, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series Slicing Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    loc and iloc\n",
    "    at and iat\n",
    "    ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LABEL BASED INDEXER METHOD\n",
    "my_series.loc?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series.loc[['a', 'c', 'e']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# INTERGER BASED INDEXER METHOD\n",
    "my_series.iloc?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series.iloc[2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MIXED LABELS and INTEGERS BASED INDEXER METHOD\n",
    "my_series.ix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series.ix['a':'c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series.ix[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boolean Series and Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use conditional operators to create an equal-length Boolean series\n",
    "- Subset the series using this boolean inside square brackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ser_x = my_series.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "positives = []\n",
    "for i in ser_x:\n",
    "    if i > 0:\n",
    "        positives.append(round(i, 2))        \n",
    "positives        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "positives = ser_x[ser_x > 0]\n",
    "positives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pd.Series.ix?\n",
    "\n",
    "``.ix[]`` supports mixed integer and label based access. It is\n",
    "primarily label based, but will fall back to integer positional\n",
    "access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series.ix[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series.ix['c':'e']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series Methods for finding the biggest values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series.idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Array Operations on a Series\n",
    "Array operations on the Series preserves the index-value links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_x2 = Series(range(4, 21, 4))\n",
    "print ser_x2\n",
    "\n",
    "np.sqrt(ser_x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series_2 = Series({'c': 1, 'd': 0.14, 'e':10, 'f': 2, 'g':-0.5})\n",
    "print my_series,'\\n', my_series_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print my_series + my_series_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods that apply to dicts are also valid on a Series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Check if an item exists in a Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'boo' in my_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## THE `.isin()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pls = Series(['c', 'py', 'java', 'scala'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-pls.isin(['c', 'py'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pls[pls.isin(['java', 'py'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reindexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series[['a', 'y', 'b', 'd', 'e', 'x']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series.reindex(['a', 'y', 'b', 'd', 'e', 'x'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Detect Missing Values\n",
    "\n",
    "\n",
    "- Missing values appear as NaN. Funtions _isnull_ and _notnull_ are used to detect missings.\n",
    "- They both produce booleans that can be used for subsetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = Series(data = [18, None, 5, None, 13], \n",
    "                index=['DEL', 'BOM', 'BLR', 'DXB', 'BKK'])\n",
    "cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series.isnull?\n",
    "pd.Series.notnull?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print zip(cities, cities.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip(cities, cities.notnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities[cities.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities[cities.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2 = ['a', 'd', 'e', 'f', 'g']\n",
    "my_series2 = my_series[index2]\n",
    "my_series2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series2[my_series2.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series2[my_series2.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series2.fillna(-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.fillna(cities.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference between None and NaN\n",
    "\n",
    "<big><br>\n",
    "\n",
    "- `NaN` is a mathematical entity\n",
    "- `None` is for missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool(np.nan)\n",
    "# Truthiness value of np.nan is True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series Methods do not discriminate between None and NaN\n",
    "Series({'a': None, 'c': 101, 'b': np.nan, 'd': 'red'}).isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<big>\n",
    "\n",
    "Task: Generate a Series of 150 ages with a mean of 35 years. Set every fifteenth value to missing. Find the nexw mean. Fill the missing data with (a) mean (b) median, and report the new means\n",
    "\n",
    "hint: use `np.random.randn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = Series(np.random.normal(loc=35, scale=1, size=1500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages.plot.hist(bins=20, xlim=(30, 40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages[::15] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages.fillna(ages.mean()).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages.fillna(ages.median()).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strategies for dealing with missing data\n",
    "\n",
    "---\n",
    "\n",
    "1. Drop if there aren't too many missings\n",
    "2. Impute with 0s (for quantities like Amounts), with Mean (for a symmetric distribution), with Median for an Asymmetric Distribution\n",
    "3. Impute by cluster mean/median\n",
    "4. Use kNN/Regression where the variable with missings = DV, others are IVs. Predict the missing data.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 Alignment in Arithmetic Operations\n",
    "Series with different indexes will be automatically aligned, and NaNs induced in locations where data is not found. \n",
    "\n",
    "The indexes are _unioned_.\n",
    "\n",
    "> Think of binary operations as outer joins. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series2 = Series(range(5), index=list('cdefg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series have different indexes\n",
    "# The indexes are UNION'd\n",
    "# Missing values used where there isnt a match.\n",
    "my_series + my_series2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series > my_series2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Series Methods - Important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe method on char series\n",
    "Series(list('Dogs are descended from wolves.')).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe method on numeric series\n",
    "ser_x = Series(np.random.normal(0, 1, 10000))\n",
    "ser_x.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_x.describe(percentiles=[0.01, 0.05, 0.97, 0.99], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_x.describe().loc[['min', 'mean', '50%', 'max']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Series methods using the Titanic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_x.loc[:, 'Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_x.loc[0, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `value_counts()` for frequency tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x['Embarked'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x['Embarked'].value_counts().plot.bar(figsize=(3, 3));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<big>\n",
    "this is equivalent to\n",
    "\n",
    "    SELECT distinct Embarked, count(*) \n",
    "    from titanic \n",
    "    group by 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `astype()` for type conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x['PassengerId'].head().astype(float).astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `map()` for applying a function to each element of a series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x['Fare'].head().map(lambda x: 'Rs. ' + str(int(x * 65.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x['Age'].head().map(lambda x: x-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_x['Name'].head().map(lambda x: 'Female' if (('Mrs' in x) or ('Miss' in x)) else 'Male' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x['Sex'].head().map(lambda x: x.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x['Name'].head().map(lambda x: (x[:20], len(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `idxmax()` for finding where the maximum value occured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fares = Series(df_x['Fare'].values, index=df_x['Name'].values)\n",
    "print fares.head()\n",
    "print fares.idxmax(), fares.idxmin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `.sort_values()` to sort a series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fares.sort_values(ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `plot()` to visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fares.plot.hist(figsize=(5, 3));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x['Embarked'].value_counts().plot.barh(figsize=(3, 3));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x[['Age', 'Fare']].plot.box(figsize=(4, 2), ylim=(0, 80), subplots=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `replace()` method for replacing values using a dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fruits = Series(['apples', 'oranges', 'peaches', 'mangoes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep = {'apples':'bananas', 'peaches':'grapes'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruits.replace(rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `duplicated()` and `drop_duplicates()` creates a boolean to indicate where duplicates occured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ser_d = Series(list('ABCDEFABGHIABCD'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip(ser_d, ser_d.duplicated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_d[-ser_d.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_d.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_d[-ser_d.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_with_dups = Series(list('ABCDEFABGHIABCD'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_with_dups.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_with_dups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ser_with_dups.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_with_dups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perx = df_x.Fare.describe(percentiles=[0.95])['95%']\n",
    "# or: df_x.Fare.quantile(0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x.Fare.clip_upper(perx).plot.hist(figsize=(3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = pd.read_csv('train.csv')\n",
    "df_x.Fare.plot.hist(figsize=(3, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<center>\n",
    "\n",
    "# $DataFrame$\n",
    "\n",
    "</center>\n",
    "---\n",
    "\n",
    "It is 2-D table like data structure that has both a row and column index. Similar to the R data frame. Each column can be a different dtype. \n",
    "\n",
    "Can be thought of a dict of Series objects.\n",
    "One of the most common ways of creating a dataframe is from a dictionary of arrays or lists.\n",
    "\n",
    "### 2.1 Creating a DataFrame\n",
    "_Syntax_: `DataFrame(data=, index=, columns=)`\n",
    "\n",
    "`data` could be a dict of equal length lists or numPy arrays.\n",
    "\n",
    "***NOTE***: Each axis has an index (which is a self contained data structure), that is used to implement\n",
    "+ Fast lookups\n",
    "+ Data alignment and joins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Creating a DataFrame from a 2D Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D array\n",
    "np.arange(20, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D array converted to 2D\n",
    "np.arange(20, 32).reshape(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DF using all defaults\n",
    "DataFrame(np.arange(20, 32).reshape(3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DF using specific declarations\n",
    "DataFrame(data = np.arange(20, 32).reshape(3, 4), \n",
    "          columns = list('WXYZ'), \n",
    "          index = list('ABC'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_df = DataFrame(np.random.random(16).reshape(4, 4), \n",
    "                  columns=['c1', 'c2', 'c3', 'c4'], \n",
    "                  index=['r1', 'r2', 'r3', 'r4']).round(2)\n",
    "print my_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To rearrange columns pass the desired order as a list of colnames\n",
    "my_df.loc[['r2', 'r4'], ['c4', 'c2', 'c3', 'c1']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating DataFrame using dict of equal length lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "my_dict = {'ints': np.arange(5),\n",
    "           'floats': np.arange(0.1, 0.6, 0.1),\n",
    "          'strings': list('abcde')}\n",
    "my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df2 = DataFrame(my_dict, \n",
    "                   index=list('vwxyz'))\n",
    "my_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Subsetting a column from a DataFrame using `[]` or `[[]]`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_1 = np.random.randn(56).reshape(7, 8).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_1 = DataFrame(arr_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_1[:5, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.iloc[:5, :5].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<big>\n",
    "\n",
    "The difference between a single `[]` accessor and `[[]]` is that the latter always produces\n",
    "a DataFrame, while the former always produces a Series.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset one column\n",
    "print type(my_df2['floats'])\n",
    "my_df2['floats']\n",
    "     # my_df2.loc[:, 'floats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset one column\n",
    "print type(my_df2[['floats']])\n",
    "my_df2[['floats']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df2[['ints', 'floats']]\n",
    "    # or, my_df2.loc[:, ['ints', 'floats']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a column to a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print my_df2\n",
    "print\n",
    "\n",
    "## Add a NEW column to a DataFrame\n",
    "my_df2['bools'] = [True, False, True, True, False]\n",
    "print my_df2\n",
    "print \n",
    "\n",
    "# Creating a derived column\n",
    "my_df2['ints2'] = my_df2['ints'] * 7 \n",
    "print my_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df2.loc[:, 'strings'] = my_df2['strings'].map(lambda x: x.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print my_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Drop Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df2.drop('ints2', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print my_df2.drop('ints2', axis='columns', inplace=True)\n",
    "\n",
    "# for permanent deletion, use inplace = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_1.shape\n",
    "# without parentheses => attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_1.sum()\n",
    "# with parenthese => method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Pandas DataFrame Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_1.shape\n",
    "# without parentheses => attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_1.sum()\n",
    "# with parenthese => method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_titanic = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Attributes | Definition \n",
    "\n",
    "T \t    Transpose index and columns \n",
    "\n",
    "at\t    Fast label-based scalar accessor \n",
    "iat  \tFast integer location scalar accessor.\n",
    "ix\t    A primarily label-location based indexer, with integer position fallback.\n",
    "loc\t    Purely label-location based indexer for selection by label.\n",
    "iloc\tPurely integer-location based indexing for selection by position.\n",
    "\n",
    "axes    Return a list with the row axis labels and column axis labels as the only members.\n",
    "\n",
    "empty\tTrue if NDFrame is entirely empty [no items]\n",
    "blocks\tInternal property, property synonym for as_blocks()\n",
    "\n",
    "dtypes\tReturn the dtypes in this object\n",
    "ftypes\tReturn the ftypes (indication of sparse/dense and dtype) in this object.\n",
    "\n",
    "ndim\tNumber of axes / array dimensions\n",
    "shape\tReturn a tuple representing the dimensionality of the DataFrame.\n",
    "size\tnumber of elements in the NDFrame\n",
    "style\tProperty returning a Styler object containing methods for building a styled HTML   representation fo the DataFrame.\n",
    "values\tNumpy representation of NDFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose\n",
    "my_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Subset using label lists\n",
    "my_df.loc[['r1', 'r2'], ['c3', 'c4']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset using label slices\n",
    "my_df.loc['r1':'r3', 'c1':'c2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset using integer lists\n",
    "my_df.iloc[[0, 2], [2, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x.get_dtype_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Pandas DataFrame Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selected few DataFrame methods:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - the `.to_csv` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataFrame.to_\n",
    "# explore write methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in os.listdir(os.getcwd()) if '.csv' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUtput to CSV\n",
    "my_df2.to_csv('my_df2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in os.listdir(os.getcwd()) if '.csv' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -2 my_df2.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - The `drop` method \n",
    "\n",
    "- Remove one or more rows (default action)\n",
    "- Remove one or more columns (pass axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop a row\n",
    "my_df2.drop('v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop a column\n",
    "my_df2.drop('ints2', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting a column\n",
    "del my_df2['const']; my_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - the math methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print my_df.sum()\n",
    "my_df.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print my_df.mean()\n",
    "my_df.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df.std(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.groupby(['Pclass', 'Sex'])['Survived'].quantile([0.5, 0.75, 0.95]).unstack().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(data=df_titanic, index='Pclass', columns='Sex', values='Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.describe(include=[object])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_titanic.loc[:, df_titanic.dtypes[(df_titanic.dtypes == object)].index.tolist()].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Revision Task`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'country': ['Belgium', 'France', 'Germany', 'Netherlands', 'United Kingdom'],\n",
    "        'population': [11.3, 64.3, 81.3, 16.9, 64.9],\n",
    "        'area': [30510, 671308, 357050, 41526, 244820],\n",
    "        'capital': ['Brussels', 'Paris', 'Berlin', 'Amsterdam', 'London']}\n",
    "\n",
    "countries = DataFrame(data, index=list('pqrst'))\n",
    "\n",
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.loc[countries['country'] == 'Germany', 'population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.set_index('country').loc['Germany', 'population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.loc[countries['population']>50, ['capital', 'area']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check row names\n",
    "countries.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check column names\n",
    "countries.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check the data types of the different columns:\n",
    "countries.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview of the data\n",
    "countries.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Setting an arbitrary Index\n",
    "If we don't like what the index looks like, we can reset it and set one of our columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- the `set_index()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'country': ['Belgium', 'France', 'Germany', 'Netherlands', 'United Kingdom'],\n",
    "        'population': [11.3, 64.3, 81.3, 16.9, 64.9],\n",
    "        'area': [30510, 671308, 357050, 41526, 244820],\n",
    "        'capital': ['Brussels', 'Paris', 'Berlin', 'Amsterdam', 'London']}\n",
    "\n",
    "countries = DataFrame(data, index=list('pqrst'))\n",
    "\n",
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "countries.index = list('uvwxy')\n",
    "# manually provided index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "countries.set_index('country', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.loc['Belgium':'Netherlands']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.loc['Belgium', 'population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "countries.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.set_index(['country', 'capital'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Some DataFrame Methods\n",
    "\n",
    "*** --- `sort_values()`:  *** used to sort the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "countries.sort_values(by='population', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "countries.sort_values(by=['population', 'area'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**--- create a new column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries['pop_density'] = countries['population'] / countries['area'] * 10000\n",
    "countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** --- `describe(): `*** computes summary statistics for each column numerical (default) column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** --- `plot(): `*** used to quickly visualize the data in different ways\n",
    "\n",
    "The available plotting types: line (default), bar, barh, hist, box , kde, area, pie, scatter, hexbin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries[['population', 'pop_density']].plot.scatter(x='population', \n",
    "                                                      y='pop_density', \n",
    "                                                      figsize=(3,3));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Barplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.set_index('country').loc[:, 'population'].sort_values().plot.barh(figsize=(4, 3))\n",
    "plt.savefig('countries_barplot.png', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in os.listdir(os.getcwd()) if 'jpg' in x or 'png' in x or 'jpeg' in x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Subsetting a DataFrame\n",
    "\n",
    "*** --- 1 Column***: For a DataFrame, basic indexing selects the columns.\n",
    "\n",
    "An individual column can be retrieved as a Series using `df['col']` or `df.col` \n",
    "\n",
    "This is especially helpful for creating boolean indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subsetting one column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df2['floats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df2[['floats']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df2.floats\n",
    "my_df2['floats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all(countries.area == countries['area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all(my_df2[['floats']] == my_df2['floats'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** --- 2+ Columns***: Multiple columns are retrieved as a DataFrame using a list of column names `df[['col1', 'col2']]` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(my_df2[['ints', 'strings']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries[['area', 'population']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** --- Rows***: can be retrieved by position or name by methods such as ***.ix***\n",
    "It provides the label indexing facility.\n",
    "\n",
    "\n",
    "This is a very powerful method that can subset the DataFrame in any way (using locations or index or ranges)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    ".loc and .iloc\n",
    ".ix\n",
    ".at and .iat\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advaned Indexing - 1 [.loc and .iloc]\n",
    "\n",
    "For more advanced indexing, you have some extra attributes:\n",
    "\n",
    "***--- loc:*** selection by label\n",
    "\n",
    "`Syntax: df.loc[[indices], [colnames]]`\n",
    "\n",
    "`[indices]` could be specified as a list, splice (start : end) or using a boolean series.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a row index (before comma) and a column name (after comma)\n",
    "countries.loc[['Germany', 'United Kingdom'], \n",
    "              ['area', 'capital']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a row index splice and a column index splice\n",
    "countries.loc['Belgium':'Germany', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.loc['Belgium':'Germany', 'area':'population']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subsetting with Booleans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(countries['population'] > 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.loc[countries['population'] > 50, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.population > 50\n",
    "# Created using the dataframe\n",
    "# The index-value links are preserved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Series([False, True, True, False, True])\n",
    "# Arbit series\n",
    "# Doesnt have the same index as the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.loc[countries.population > 50, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "countries.loc[Series([False, True, True, False, True]), :]\n",
    "# Gives you an Indexing Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - The `reset_index()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "countries.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Using Comprehensions to subset rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['France' in x for x in countries.country]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.loc[['France' in x for x in countries.country], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(('area' in x) or ('capital' in x)) for x in countries.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.loc[['France' in x for x in countries.set_index('country').index],\n",
    "             [(('area' in x) or ('capital' in x)) for x in countries.columns]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a boolean for rows and a list of column names\n",
    "countries.loc[countries['population'] > 5, ['capital', 'area']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *** --- iloc:*** selection by position.\n",
    "\n",
    "Selecting by position with iloc works similar as indexing numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using splices for both rows and columns\n",
    "countries.iloc[1:4, 1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: The different indexing methods can also be used to assign data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advaned Indexing - 2 [using the ***.ix*** method]\n",
    "\n",
    "\n",
    "\n",
    "`Syntax: df.ix[<specify-rows>, <specify-cols>]`\n",
    "\n",
    "- Here, `specify-cols` could be done as a singular/list/splice of colname(s)\n",
    "    - Additionally, we could even specify integer ranges (splices).\n",
    "\n",
    "- Similarly, `specify-rows` can be done using indices (if you want to subset rows by name)\n",
    "    - by using integer splices (if you want to subset by position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Columns\n",
    "\n",
    "# select a column by name\n",
    "my_df2.ix[:, 'strings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select multiple columns by name\n",
    "my_df2.ix[:, ['strings', 'floats']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select columns by position\n",
    "print my_df2.ix[:, 0:2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetting Rows using integers and ix\n",
    "print my_df2.ix[0, :] # first row\n",
    "print my_df2.ix[2, :] # second row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print my_df2.ix[0:2] # by position: returns the first 2 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetting rows using labels and .ix\n",
    "\n",
    "print my_df2.ix['x':'z'] # by index: returns the last three rows\n",
    "# We can slice the DataFrame using an index object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the :: for stepping through rows\n",
    "my_df2.ix[::-1, ['strings', 'ints']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df2.ix[0:5:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE:\n",
    "\n",
    "> The column returned when indexing a DataFrame is a view on the underlying\n",
    "data, not a copy. Thus, any in-place modifications to the Series\n",
    "will be reflected in the DataFrame. The column can be explicitly copied\n",
    "using the Seriess copy method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = countries['capital']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap[1] = 'Paris'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Reindexing\n",
    "It is used to create a DF with the data _conformed_ to a new index.\n",
    "\n",
    "If we subset a Series or DataFrame with an index object, \n",
    "\n",
    "the data is _rearranged_ to obey this new index and missing values are introduced wherever the data was not present\n",
    "\n",
    "#### --- Reindexing a Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.set_index('capital', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "capital2 = ['Paris', 'Brussels', 'Munich', 'Amsterdam', 'Manchester', 'Madrid']\n",
    "\n",
    "countries.loc[capital2, :].fillna('Info NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.reindex(capital2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --- Reindexing a DataFrame\n",
    "\n",
    "`Syntax: df.reindex(index=, columns=, fill_value=, method=)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = DataFrame(np.random.randn(9).reshape(3, 3), index=list('acd'), columns=list('zwx')); frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.reindex(list('abcde'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.reindex(index=list('abcde'), \n",
    "              columns=list('wxyz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ffill will copy values from the previous row where possible, and if an entire column is NaN, fill_value will populate it.\n",
    "(frame\n",
    " .reindex(index=list('abcde'), columns=list('wxyz'),\n",
    "          method='ffill',\n",
    "          fill_value=0.1)\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df2.reindex(index=df1.index,\n",
    "           columns=df1.columns,\n",
    "           method='ffill', fill_value=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> NOTE: `reindex` is quite helpful to align dataFrames for merging/appending tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Operations involving DataFrames: _Data Alignment by Index_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = DataFrame(data=np.arange(1, 13).reshape(4,3), index=list('abcd'), columns=list('pqr'))\n",
    "df2 = DataFrame(data=np.arange(1, 13).reshape(3,4), index=list('abc'), columns=list('pqrs')) \n",
    "print 'df1', '\\n', df1, '\\n'\n",
    "print 'df2', '\\n', df2, '\\n'\n",
    "print 'df1 + df2', '\\n', df1 + df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note***: Alignments happen on both axes. No information is discarded by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We could choose to get rid of or impute missing rows/columns\n",
    "(df1 + df2).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<big>\n",
    "\n",
    "## Task 1\n",
    "\n",
    "- Import the data into Pandas '`train.csv`'\n",
    "    - Report the shape of the table and the data type of each column.\n",
    "\n",
    "- Subset the data to retain only the passengers that survived. Name this object 'Survivors'\n",
    "    - Within the 'survivors' find the summary statistics of the 'Age' and 'Fare' variables.\n",
    "\n",
    "- Subset the data to retain only Female passengers.\n",
    "    - Find out how many females over the age of 30 survived.\n",
    "\n",
    "- Are there any missing values in the Age column?    \n",
    "    - Draw a histogram of this column.\n",
    "    - Replace missing values with a) Mean b) Median\n",
    "    - Report the new summary statistics on this variable\n",
    "---    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.loc[df_titanic['Survived'] == 1, ['Age', 'Fare']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_titanic.loc[((df_titanic['Sex'] == 'female') & (df_titanic['Survived'] == 1)) , 'Age'] > 30).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic['Age'].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic['Age'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic['Age'].plot.hist(figsize=(3, 3));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_mean = df_titanic['Age'].mean()\n",
    "df_titanic['Age'].fillna(age_mean).plot.hist(figsize=(3, 3));\n",
    "# replace missings with mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic['Age'].fillna(df_titanic['Age'].median()).plot.hist(figsize=(3, 3));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2.7 Deleting Rows or Colums\n",
    "\n",
    "This can be done using the `drop` method and specifying row indices or column names.\n",
    "\n",
    "To drop **rows**\n",
    "\n",
    "`Syntax: df.drop(indices-as-a-list)`\n",
    "\n",
    "To drop **columns**\n",
    "\n",
    "`Syntax: df.drop(colnames-as-a-list, axis=1)`\n",
    "\n",
    "\n",
    "Parameters \n",
    "\n",
    "- axis (controls row/col deletion)\n",
    "- inplace (changes to be permanent or not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the row with index 'b'\n",
    "df1.drop('b', inplace=True); df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the column with name 'q'\n",
    "df1.drop('q', axis=1, inplace=True); df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove multiple rows\n",
    "df2.drop(['a', 'b'], inplace=True); df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Using Boolean Indexing to conditionally replace data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print df1, '\\n', df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3 = df1 + df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df3.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[df3.isnull()] = -99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[df3>8] = 99; df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d11 = DataFrame(np.random.randn(25).reshape(5,5), \n",
    "index=list('abcde'), \n",
    "columns=list('vwxyz')).round(2); print d11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d11.quantile(np.arange(0.25, 1, 0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d11.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8 Apply functions to each element/rows or columns of a DataFrame\n",
    "\n",
    "Using \n",
    "\n",
    "- **`s.map()`**, apply a func to each element of a Series\n",
    "- **`df.applymap()`** apply a func to each element of a DF\n",
    "- **`df.apply()`** apply a func to rows/columns of a DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Lambda functions are also known as ANONYMOUS functions because they typically do not have a name.\n",
    "\n",
    "- The are used extensively in Python, and even more with the map, applymap and apply functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame(arr_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame(arr_1).applymap(lambda x: 'neg' if x < 0 else 'pos')\n",
    "# a function that checks if value is less than 0, then says 'neg' for negative or 'pos' for positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Named Function\n",
    "def addTen(x):\n",
    "    return x + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addTen(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe to work with\n",
    "df8 = DataFrame(np.random.randn(25).reshape(5, 5), \n",
    "                index=list('abcde'), \n",
    "                columns=list('vwxyz')).round(2); df8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8.1 Apply a function to each element\n",
    "\n",
    "--- Calling ***numPy ufuncs*** on DataFrame objects will apply the function to each element\n",
    "\n",
    "> ufuncs work on a single argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(df8.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(df8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8.applymap(np.abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "np.abs(df8)\n",
    "## This is an example of a VECTORIZED OPERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "df8.applymap(np.abs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> It is possible to ***apply a udf to each element*** in a Series (using **`map`**) or a DataFrame (using **`applymap`**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function that formats a number to 2 decimal places\n",
    "format8 = lambda x: '%.1f' %x\n",
    "\n",
    "# SAME AS\n",
    "# def format8(x):\n",
    "#     return '%.2f' %x\n",
    "\n",
    "format8(3.1341)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df8.applymap(format8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.8.2 Apply a udf to each row/column\n",
    "\n",
    "Using the `.apply(func, axis=)` method to a DataFrame does this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%timeit df8.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8.apply(np.mean, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit df8.apply(mean, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8.max(axis=1)\n",
    "# apply is implied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8.apply(max, axis=1)\n",
    "# apply is explicitly mentioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8.apply(lambda x: (x.max() - x.min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Using different functions with `apply()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<big>\n",
    "\n",
    "When you write a lambda function to work with apply on a dataframe, remember\n",
    "\n",
    "1. The input to the function will be a SERIES.\n",
    "2. The output can be a number or a series.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a general function that returns multiple values\n",
    "def func8(x):\n",
    "    return Series([x.min(), x.mean(), x.max()], \n",
    "                  index=['MIN.', 'MEAN.', 'MAX.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_1 = Series(np.random.randn(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func8(s_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8.apply(func8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8.apply(func8, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Big Task \n",
    "\n",
    "---\n",
    "\n",
    "Create a function called DESCRIBE_X that takes as input a Series, \n",
    "and produces a series containing\n",
    "\n",
    "- `min, max, sum, mean, std, missings, nonmissings, skew, kurtosis`\n",
    "- `percentiles - as specified by the user`\n",
    "\n",
    "---\n",
    "\n",
    "`DESCRIBE_X(s_1, percentiles=[0.1, 0.3, 0.92, 0.99]`\n",
    "\n",
    "---\n",
    "\n",
    "Output\n",
    "\n",
    "min\n",
    "max\n",
    "sum\n",
    "mean\n",
    "std\n",
    "0.1\n",
    "0.3\n",
    "0.92\n",
    "0.99\n",
    "\n",
    "---\n",
    "\n",
    "Then, apply this function to the rows, columns of arr_1 as a DataFrame.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "## Task 2\n",
    "\n",
    "- Define a function call 'Standardizing' which works on a series as:\n",
    "    - Find the mean and standard deviation of the series\n",
    "    - Subtract each value of the series with the mean\n",
    "    - Divide the result with the standard deviation\n",
    "    - Apply this function to each numerical column (int or float) of the Titanic Dataset\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Solution to task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load task_describe_X.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DESCRIBE_X(s=Series(np.random.random(100)), perc=[0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_1 = DataFrame(np.random.randn(5000).reshape(1000, 5), columns=['Col_' + str(i) for i in range(5)])\n",
    "arr_1.apply(lambda c: DESCRIBE_X(s=c, perc=[0.1, 0.2, 0.8, 0.9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Solution to task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4 = DataFrame(np.random.randn(1000).reshape(200, 5), \n",
    "                 columns=['Col_' + str(x) for x in range(5)]); df_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_4_NORM = df_4.apply(lambda s: (s - s.mean())/s.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4_NORM.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4_NORM.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revision Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a 500 x 10 matrix/DataFrame filled with random numbers.\n",
    "Name the columns as Col_1 ... Col_10\n",
    "\n",
    "Declare a function that operates on a Series (hence row or column) and returns the square root of the sum of squares of the min and max numbers in each\n",
    "\n",
    "1. Row\n",
    "2. Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 2.9 Sorting \n",
    "\n",
    "** 2.9.1 Sorting a Series ** \n",
    "\n",
    "To sort a series on its index, use \n",
    "- `my_series.sort_index()`\n",
    "\n",
    "To sort a series on its values, use \n",
    "- `my_series.sort_values(ascending=<bool>)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Series with explicit index \n",
    "s9 = Series(np.random.randint(0, 50, 5), \n",
    "            index=list('dcbae')); s9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s9.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s9.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting on the index\n",
    "s9.sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting on the values \n",
    "s9.sort_values(ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ** 2.9.2 Sorting a DataFrame**\n",
    "\n",
    "Here we use the `sort_index()` method and specify what columns to sort on using `by=`, and the order of sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d9 = DataFrame(np.random.randint(0, 100, 30).reshape(10, 3), \n",
    "               index=list('abcdefghij'), \n",
    "               columns=list('prq')); d9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d9.sort_values(by='p', ascending=False, inplace=True); d9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d9.sort_values(by=['p', 'q'], ascending=False, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d9.sort_index? \n",
    "# Sort DataFrame either by labels (along either axis) or by the values in a column\n",
    "\n",
    "d9.sort_index(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.sort_values(by=['Age', 'Pclass'], ascending=False)[['Name','Age', 'Pclass']][5:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Reordering rows or columns **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without arguments, it will sort the index of the dataframe\n",
    "d9.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To sort column names\n",
    "d9.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Sorting on values **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the data by the values of a column\n",
    "d9.sort_values(by='q', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the data by the values of 2 columns\n",
    "d9.sort_values(by=['p', 'r'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.10 Ranking\n",
    "\n",
    "This can be done by calling the `.rank()` method on a Series\n",
    "\n",
    "`Syntax: obj.rank(axis=, ascending=, method=)`\n",
    "\n",
    "Here, `method` refers to the method used to break ties if different elements have the same values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s9 = Series(np.random.randint(0, 100, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s9.rank()\n",
    "# .astype(int) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a series\n",
    "s1 = Series(np.random.randint(80, 100, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1.rank(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with series, ranks as the 2 columns\n",
    "DataFrame({'a': s1, 'b': s1.rank(ascending=False)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.11 Descriptive Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Categorical Data **\n",
    "\n",
    "- Calling describe() on a Categorical object shows count, # of unique, mode, mode's frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print Series(list('abcxyzbbc'))\n",
    "\n",
    "Series(list('abcxyzbbc')).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Series(list('abc')*4).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic['Embarked'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ** Numeric Data **\n",
    "\n",
    "Pandas objects have a set of common math/stat methods that extract\n",
    "\n",
    "--- a single value from a Series\n",
    "\n",
    "--- a Series from a DataFrame (along a specified axis)\n",
    "\n",
    "Methods include:\n",
    "\n",
    "`count, sum, mean, median, min/max, idxmin/idxmax, skew, kurt, cumsum, cumprod, pct_change` and more.\n",
    "\n",
    "> Note that these methods would be applied over each row/column as specified and results collated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d11 = DataFrame(np.random.randint(0, 100, 25).reshape(5, 5), \n",
    "                index=list('abcde'), \n",
    "                columns=list('vwxyz')); print d11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting colsums is as simple as calling the .sum() method of a DataFrame\n",
    "print d11.sum()\n",
    "print d11.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working on rows would require you to pass axis=1 to the .sum() method\n",
    "d11.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note that missing values are ignored by default. Pass `skipna=False` to disable this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the min/max for each column/row\n",
    "d11.min(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 2\n",
    "\n",
    "- is .sum() faster or using np.sum in an apply function\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit d11.apply(lambda x: np.sum(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit d11.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locate the min and max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where does this value occur?\n",
    "d11['v'].idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d11.ix['d'].idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `describe()` works on all numeric (int or float) columns in a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d11.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate quantiles for each column \n",
    "titanic.quantile(np.arange(0.80, 1, 0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 3"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "For Titanic Data, produce a function called DESCRIBE()\n",
    "\n",
    "- in addition to the pandas describe() output \n",
    "- provide percentiles from 80 to 95 at an interval of 5\n",
    "\n",
    "in a single table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(titanic\n",
    " .describe()\n",
    " .append(titanic.quantile(np.arange(0.80, 1, 0.05))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Two Numerical Variables: Correlation\n",
    "\n",
    "DataFrames have `.corr()` and `.cov()` methods that return a full correlation/covariance matrix as a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = DataFrame({'a': np.random.randn(1000), 'b': np.random.randn(1000)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "df_1.plot.scatter(x='a', y='b', figsize=(3, 3));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Correlation Coefficient b/w Var A and Var B is ... \", df_1.corr().loc['a', 'b']\n",
    "\n",
    "# produce a correlation matrix, filled with correlation coefficients\n",
    "# between any two variables, the corr coeff measures the strength of the relationship\n",
    "\n",
    "# coeff close to zero means NO RELATIONSHIP\n",
    "# coeff close to +1 means STRONG POSITIVE RELATIONSHIP (directly proportional)\n",
    "# coeff close to -1 means STRONG NEGATIVE RELATIONSHIP (inversely proportional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/d4/Correlation_examples2.svg/2000px-Correlation_examples2.svg.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df_1.assign(c = lambda d: -4 * d['a'] + 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.plot.scatter(x='a', y='c', figsize=(4, 4));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncorrelated Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(DataFrame(np.random.randint(0, 1000, 5000).reshape(2500, 2), \n",
    "          columns=['X', 'Y'])\n",
    ".plot.scatter(x='X', y='Y', figsize=(3, 3)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(DataFrame(np.random.randint(0, 1000, 5000).reshape(2500, 2), \n",
    "          columns=['X', 'Y'])).corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positively Correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.randint(0, 1000, 2500)\n",
    "Y = 4 * X + 25 + 1000 * np.sin(X) + np.random.randint(0, 200, 2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame({'X': X, 'Y': Y}).plot.scatter(x='X', y='Y', figsize=(3, 3));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame({'X': X, 'Y': Y}).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_titanic = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.describe().columns.tolist()[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df_titanic[df_titanic.describe().columns.tolist()[-4:]].corr().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Correlation Matrix\n",
    "sns.heatmap(d11.corr().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(titanic[['PassengerId', 'Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']].fillna(0).corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<big>  Task\n",
    "    \n",
    "- Find the correlation matrix for the Titanic data\n",
    "\n",
    "- Report the correlation (and your interpretation) between \n",
    "    - Age and Fare \n",
    "\n",
    "- print only the correlation values that are above 0.7 (or below -0.7)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.12 More Methods for Pandas objects\n",
    "\n",
    "Now we look at methods for unique values (`unique`), frequency tables (`value_counts`), membership (`isin`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting distinct values in a Series\n",
    "s12 = Series(list('the quick brown fox jumped over the lazy dog'))\n",
    "\n",
    "set(s12) \n",
    "#  or\n",
    "s12.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s12.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.Survived.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the `isin` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isin returns a boolean that can be used to index the original value\n",
    "s12.isin(list('pqrst'))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print titanic.Sex.head()\n",
    "\n",
    "titanic.Sex.head().isin(['male'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colours = Series(['red', 'blue', 'white', 'green', 'black', 'white', None])\n",
    "\n",
    "print colours.isin(['white', 'blue', None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference between `None` and `np.nan`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type(np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.12 Handling Missing Data\n",
    "\n",
    "Pandas treats the numpy `NaN` and the Python `None` as missing values.\n",
    "\n",
    "--- These can be **detected** in a Series or DataFrame using **`obj.notnull()`**,  **`obj.isnull()`** which returns a boolean.\n",
    "\n",
    "--- **To filter out missing data** from a Series, or to remove rows (default action) or columns with missing data in a DataFrame, we use **`obj.dropna()`**\n",
    "\n",
    "--- Missing Value **imputation** is done using the **`obj.fillna()`** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a string Series and set some values to missing\n",
    "s12 = Series(['abc', 'pqr', np.nan, 'xyz', np.nan, 'ijk', None])\n",
    "\n",
    "s12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect missing values\n",
    "s12.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values with 0\n",
    "s12.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s12.fillna('missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s12.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s12.fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a numeric Series and set a few values to missing\n",
    "s13 = Series(np.random.randint(0, 50, 16), index=list('abcdefghabcdefgh'))\n",
    "s13[::2] = np.nan\n",
    "s13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fill with median\n",
    "s13.fillna(s13.median())\n",
    "\n",
    "# We could use 0, or .mean() or some arbitrary method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s13.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<big>\n",
    "\n",
    "\n",
    "### How to fill missing values?\n",
    "\n",
    "- It depends on the type of your variable.\n",
    "\n",
    "For numeric, two methods.\n",
    "Use Median if data is skewed, else use Mean.\n",
    "\n",
    "For categorical, use Mode.\n",
    "\n",
    "----\n",
    "\n",
    "#### Task\n",
    "\n",
    "- Check which of the Titanic Data Variables have Missings.\n",
    "- Find the means\n",
    "- Impute missings with means.\n",
    "- Find the means again.\n",
    "- Have they shifted?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implementing Split-Apply-Combine: The _groupby_ method\n",
    "+ You may group along the rows or columns.\n",
    "+ Returns the groupby object that stores info on how to split the data\n",
    "+ To this object, we implement Aggregations (reduce size of data) or Transformations (no change in size) or Apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"http://i.imgur.com/yjNkiwL.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame({'floats': np.random.randn(20), \n",
    "                'string': list('a' * 4 + 'b' * 6 + 'c' * 3 + 'd' * 7)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['string'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print df.groupby('string').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print df.groupby('string').min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic = pd.read_csv('train.csv')\n",
    "\n",
    "print df_titanic.groupby('Embarked')['Fare'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print df_titanic.groupby('Embarked').apply(lambda g: g[['Fare', 'Age']].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Creating a GroupBy Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tab in grouped:\n",
    "    print type(tab)\n",
    "    print len(tab)\n",
    "    print tab[1][:3]\n",
    "    print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Series(map(lambda tup: {tup[0]: tup[1]['floats'].mean()}, grouped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print grouped.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore GroupbyObject Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specialized functions on grouped object directly\n",
    "print grouped.sum()\n",
    "print grouped.mean()\n",
    "print grouped.median()\n",
    "\n",
    "# try min, max, idxmin, idxmax and so on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### An example using the Titanic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.Embarked.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embarked\n",
       "C               (Ward, Miss. Anna, 512.3292)\n",
       "Q        (Minahan, Dr. William Edward, 90.0)\n",
       "S    (Fortune, Mr. Charles Alexander, 263.0)\n",
       "dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_titanic\n",
    " .groupby('Embarked')\n",
    " .apply(lambda x: (x.set_index('Name').loc[:, 'Fare'].idxmax(),\n",
    "                  x.set_index('Name').loc[:, 'Fare'].max())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>28.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>31.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Age  Fare\n",
       "Sex               \n",
       "female  28.0  44.0\n",
       "male    31.0  26.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_titanic\n",
    " .groupby('Sex')\n",
    " .apply(lambda x: x[['Age', 'Fare']].mean()).round(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex     Embarked  Name                                 \n",
       "female  C         Ward, Miss. Anna                         512.3292\n",
       "                  Ryerson, Miss. Susan Parker \"Suzette\"    262.3750\n",
       "        Q         Minahan, Miss. Daisy E                    90.0000\n",
       "                  Rice, Mrs. William (Margaret Norton)      29.1250\n",
       "        S         Fortune, Miss. Mabel Helen               263.0000\n",
       "                  Fortune, Miss. Alice Elizabeth           263.0000\n",
       "male    C         Lesurer, Mr. Gustave J                   512.3292\n",
       "                  Cardeza, Mr. Thomas Drake Martinez       512.3292\n",
       "        Q         Minahan, Dr. William Edward               90.0000\n",
       "                  Rice, Master. Eugene                      29.1250\n",
       "        S         Fortune, Mr. Mark                        263.0000\n",
       "                  Fortune, Mr. Charles Alexander           263.0000\n",
       "Name: Fare, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top two Fares for Sex x Embarked categories\n",
    "\n",
    "(df_titanic\n",
    " .set_index('Name')\n",
    " .groupby(['Sex', 'Embarked'])\n",
    " .apply(lambda x: x['Fare'].sort_values(ascending=False).head(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  male female\n",
    "S x     x2\n",
    "C y     y2\n",
    "Q z     z2\n",
    "\n",
    "male S x\n",
    "male C y \n",
    "male Q z\n",
    "fema S x2\n",
    "fema C y2\n",
    "feme Q z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(data = df_titanic, \n",
    "               index = 'Embarked', \n",
    "               columns = 'Sex', \n",
    "               values = 'Fare', \n",
    "               aggfunc = [np.mean, np.sum]).to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit df_titanic.query(\"Parch <= 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit df_titanic.loc[df_titanic.Parch <= 2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(data = df_titanic.query(\"Parch <= 2\"), \n",
    "               index='Pclass', \n",
    "               columns=['Sex','Parch'], \n",
    "               values='Survived').round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit pd.pivot_table(data = df_titanic, index='Pclass', values='Fare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit df_titanic.groupby('Pclass')['Fare'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<big>\n",
    "\n",
    "*Task* | Using variables Embarked, PClass and Sex find the group with the highest rate of survival.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "grps = [['Embarked'], ['Pclass'], ['Sex'], \n",
    "        ['Embarked', 'Pclass'], ['Embarked', 'Sex'], ['Pclass', 'Sex'],\n",
    "        ['Embarked', 'Pclass', 'Sex']]\n",
    "\n",
    "per_survived = {}\n",
    "\n",
    "for grp in grps:\n",
    "    per_survived['_'.join(grp)] = df_titanic.groupby(grp)['Survived'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Embarked_Pclass_Sex',\n",
       " 'Embarked',\n",
       " 'Embarked_Pclass',\n",
       " 'Embarked_Sex',\n",
       " 'Pclass',\n",
       " 'Sex',\n",
       " 'Pclass_Sex']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_survived.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_concatd = pd.concat([per_survived.get(k) for k in per_survived])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Q, 2, female)    1.000000\n",
       "(C, 2, female)    1.000000\n",
       "(Q, 1, female)    1.000000\n",
       "(C, 1, female)    0.976744\n",
       "(1, female)       0.968085\n",
       "(S, 1, female)    0.958333\n",
       "(2, female)       0.921053\n",
       "(S, 2, female)    0.910448\n",
       "(C, female)       0.876712\n",
       "(Q, female)       0.750000\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_concatd.sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Q, 2, male)    0.000000\n",
       "(Q, 1, male)    0.000000\n",
       "(Q, male)       0.073171\n",
       "(Q, 3, male)    0.076923\n",
       "(S, 3, male)    0.128302\n",
       "(3, male)       0.135447\n",
       "(S, 2, male)    0.154639\n",
       "(2, male)       0.157407\n",
       "(S, male)       0.174603\n",
       "male            0.188908\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_concatd.sort_values()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = {}\n",
    "for grp in grps:\n",
    "    sizes['_'.join(grp)] = df_titanic.groupby(grp).apply(lambda g: g.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sizes = pd.concat([sizes[k] for k in sizes.keys()])\n",
    "type(sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sizes.name = 'Num_of_Passengers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(C, 1, female)     516\n",
       "(C, 1, male)       504\n",
       "(C, 2, female)      84\n",
       "(C, 2, male)       120\n",
       "(C, 3, female)     276\n",
       "(C, 3, male)       516\n",
       "(Q, 1, female)      12\n",
       "(Q, 1, male)        12\n",
       "(Q, 2, female)      24\n",
       "(Q, 2, male)        12\n",
       "(Q, 3, female)     396\n",
       "(Q, 3, male)       468\n",
       "(S, 1, female)     576\n",
       "(S, 1, male)       948\n",
       "(S, 2, female)     804\n",
       "(S, 2, male)      1164\n",
       "(S, 3, female)    1056\n",
       "(S, 3, male)      3180\n",
       "C                 2016\n",
       "Q                  924\n",
       "S                 7728\n",
       "(C, 1)            1020\n",
       "(C, 2)             204\n",
       "(C, 3)             792\n",
       "(Q, 1)              24\n",
       "(Q, 2)              36\n",
       "(Q, 3)             864\n",
       "(S, 1)            1524\n",
       "(S, 2)            1968\n",
       "(S, 3)            4236\n",
       "(C, female)        876\n",
       "(C, male)         1140\n",
       "(Q, female)        432\n",
       "(Q, male)          492\n",
       "(S, female)       2436\n",
       "(S, male)         5292\n",
       "1                 2592\n",
       "2                 2208\n",
       "3                 5892\n",
       "female            3768\n",
       "male              6924\n",
       "(1, female)       1128\n",
       "(1, male)         1464\n",
       "(2, female)        912\n",
       "(2, male)         1296\n",
       "(3, female)       1728\n",
       "(3, male)         4164\n",
       "Name: Num_of_Passengers, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([series_concatd, sizes], axis=1)['Num_of_Passengers'].sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Num_of_Passengers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(C, 2, female)</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Q, 1, female)</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Q, 2, female)</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(C, 1, female)</th>\n",
       "      <td>0.976744</td>\n",
       "      <td>516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(1, female)</th>\n",
       "      <td>0.968085</td>\n",
       "      <td>1128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(S, 1, female)</th>\n",
       "      <td>0.958333</td>\n",
       "      <td>576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(2, female)</th>\n",
       "      <td>0.921053</td>\n",
       "      <td>912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(S, 2, female)</th>\n",
       "      <td>0.910448</td>\n",
       "      <td>804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(C, female)</th>\n",
       "      <td>0.876712</td>\n",
       "      <td>876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Q, female)</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Survived  Num_of_Passengers\n",
       "(C, 2, female)  1.000000                 84\n",
       "(Q, 1, female)  1.000000                 12\n",
       "(Q, 2, female)  1.000000                 24\n",
       "(C, 1, female)  0.976744                516\n",
       "(1, female)     0.968085               1128\n",
       "(S, 1, female)  0.958333                576\n",
       "(2, female)     0.921053                912\n",
       "(S, 2, female)  0.910448                804\n",
       "(C, female)     0.876712                876\n",
       "(Q, female)     0.750000                432"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([series_concatd, sizes], axis=1).sort_values('Survived', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Num_of_Passengers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(Q, 2, male)</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Q, 1, male)</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Q, male)</th>\n",
       "      <td>0.073171</td>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Q, 3, male)</th>\n",
       "      <td>0.076923</td>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(S, 3, male)</th>\n",
       "      <td>0.128302</td>\n",
       "      <td>3180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(3, male)</th>\n",
       "      <td>0.135447</td>\n",
       "      <td>4164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(S, 2, male)</th>\n",
       "      <td>0.154639</td>\n",
       "      <td>1164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(2, male)</th>\n",
       "      <td>0.157407</td>\n",
       "      <td>1296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(S, male)</th>\n",
       "      <td>0.174603</td>\n",
       "      <td>5292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>0.188908</td>\n",
       "      <td>6924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Survived  Num_of_Passengers\n",
       "(Q, 2, male)  0.000000                 12\n",
       "(Q, 1, male)  0.000000                 12\n",
       "(Q, male)     0.073171                492\n",
       "(Q, 3, male)  0.076923                468\n",
       "(S, 3, male)  0.128302               3180\n",
       "(3, male)     0.135447               4164\n",
       "(S, 2, male)  0.154639               1164\n",
       "(2, male)     0.157407               1296\n",
       "(S, male)     0.174603               5292\n",
       "male          0.188908               6924"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([series_concatd, sizes], axis=1).sort_values('Survived', ascending=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Reshaping your data  with  `stack, unstack and pivot_table`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LONG to WIDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'A': list('x' * 5) + list('y' * 5), \n",
    "                   'B': list('abcde' * 2),\n",
    "                   'C': np.random.randint(0, 100, 10)})\n",
    "\n",
    "df.set_index(['A', 'B'], inplace=True)\n",
    "\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.unstack(level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetting a DataFrame with Hierachical Index\n",
    "df.loc['y'].loc['a':'c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = DataFrame(np.random.randn(16).reshape(4,4), \n",
    "                 index=list('abcd'), \n",
    "                 columns=list('pqrs'))\n",
    "print 'DataFrame ... \\n', df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print '\\n\\nStacking results in one column...\\n', df_1.stack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> To use stack/unstack, we need the values we want to shift from rows to columns or the other way around as the index"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
