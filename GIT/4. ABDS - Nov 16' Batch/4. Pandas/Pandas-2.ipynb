{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing Data\n",
    "\n",
    "pandas has functions such as **`read_csv, read_table, read_fwf`** and **`read_clipboard`** for reading tabular data as a DataFrame object. These functions take as arguments the following options:\n",
    "\n",
    "* Which columns to consider?   \n",
    "    * Import the header (`header=None`) or provide column names (`names=`)\n",
    "\n",
    "* Type inference and conversion\n",
    "    * Processing dates, combining date and time\n",
    "\n",
    "* Which column serves as the index? (`index_col=`)\n",
    "    * For a hierarchical index, pass a list of column names\n",
    "    \n",
    "* Which values to interpret as missing data (`na_values=`)\n",
    "    * If there are multiple sentinels for missing data, pass a dictionary\n",
    "\n",
    "* If the file is too large, read chunks iteratively (`nrows=` and `chunksize=`)\n",
    "\n",
    "* Skipping over rows/footer (`skiprows=`)\n",
    "\n",
    "* Interpreting decimal numbers (points or commas to mark thousands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic = pd.read_csv(path + '/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.merge?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"https://adiyatmubarak.files.wordpress.com/2016/01/sql.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 7.1 Merge\n",
    "pandas.merge is similar to the _SQL join_ operations; it links rows of tables using one or more _keys_\n",
    "\n",
    "Syntax:\n",
    "\n",
    "`merge(df1, df2, \n",
    "       how='left', on='key', left_on=None, right_on=None, \n",
    "       left_index=False, right_index=False, \n",
    "       sort=True, copy=True,\n",
    "       suffixes=('_x', '_y'))`\n",
    "\n",
    "\n",
    "The syntax includes specifications of the following arguments\n",
    "\n",
    "* **Which column to merge on;** \n",
    "    * the `on='key'` if the same key is in the two DFs, \n",
    "    * or `left_on='lkey', right_on='rkey'` if the keys have different names in the DFs \n",
    "    * Note: To merge on multiple keys, pass a list of column names\n",
    " \n",
    " \n",
    "* **The nature of the join;** \n",
    "    * the `how=` option, with `left`, `right`, `outer`\n",
    "    * By default, the merge is an `inner` join\n",
    "    \n",
    " \n",
    "* Tuple of string values to append to **overlapping column names** to identify them in the merged dataset\n",
    "    * the `suffixes=` option\n",
    "    * defaults to `('_x', '_y')`\n",
    "    \n",
    " \n",
    "* If you wish **to merge on the DF index**, pass `left_index=True` or `right_index=True` or both.\n",
    "\n",
    "\n",
    "* Sort the result DataFrame by the join keys in lexicographical order or not;\n",
    "    * `sort=` option; Defaults to True, setting to False will improve performance substantially in many cases\n",
    "    \n",
    "    \n",
    "    \n",
    "> _Note:_ For the **official Documentation** refer http://pandas.pydata.org/pandas-docs/dev/merging.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   data0 key\n",
      "0     56   a\n",
      "1     35   b\n",
      "2     29   c\n",
      "3     12   d\n",
      "4     96   e \n",
      "\n",
      "   data1 key\n",
      "0     93   b\n",
      "1     54   b\n",
      "2     98   a\n",
      "3     23   c\n",
      "4     72   a\n",
      "5     92   a\n",
      "6     64   b \n",
      "\n",
      "   data2 key\n",
      "0     62   a\n",
      "1     14   b\n",
      "2     40   d\n",
      "3     52   f\n",
      "4     74   g \n",
      "\n",
      "   data3 lkey\n",
      "0     68    b\n",
      "1     62    b\n",
      "2     73    a\n",
      "3     41    c\n",
      "4     95    a\n",
      "5     40    a\n",
      "6     11    b \n",
      "\n",
      "   data4 rkey\n",
      "0     71    a\n",
      "1     91    b\n",
      "2     44    d\n"
     ]
    }
   ],
   "source": [
    "# Let's define a few toy datasets to use as examples\n",
    "\n",
    "df0 = DataFrame({'key': ['a', 'b', 'c', 'd', 'e'], 'data0': np.random.randint(0, 100, 5)})\n",
    "df1 = DataFrame({'key': ['b', 'b', 'a', 'c', 'a', 'a', 'b'], 'data1': np.random.randint(0, 100, 7)})\n",
    "df2 = DataFrame({'key': ['a', 'b', 'd', 'f', 'g'], 'data2': np.random.randint(0, 100, 5)})\n",
    "\n",
    "df3 = DataFrame({'lkey': ['b', 'b', 'a', 'c', 'a', 'a', 'b'], 'data3': np.random.randint(0, 100, 7)})\n",
    "df4 = DataFrame({'rkey': ['a', 'b', 'd'], 'data4': np.random.randint(0, 100, 3)})\n",
    "\n",
    "print df0, '\\n\\n', df1, '\\n\\n', df2, '\\n\\n', df3, '\\n\\n', df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a' 'b' 'd']\n",
      "   data0 key  data2\n",
      "0     56   a     62\n",
      "1     35   b     14\n",
      "2     12   d     40\n"
     ]
    }
   ],
   "source": [
    "# 1. Default merge with no parameters\n",
    "print np.intersect1d(df0.key, df2.key)\n",
    "\n",
    "print pd.merge(df0, df2)\n",
    "# We see that its an inner join by default (output key is the intersection of input keys)\n",
    "# Merge happens on the column 'key' which is common to both datasets;\n",
    "    # We could've written pd.merge(df1, df2, on='key', how='inner') to the same effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   data0 key  data2\n",
      "0     56   a   62.0\n",
      "1     35   b   14.0\n",
      "2     29   c    NaN\n",
      "3     12   d   40.0\n",
      "4     96   e    NaN\n"
     ]
    }
   ],
   "source": [
    "# Left Join\n",
    "print pd.merge(df0, df2, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "ename": "MergeError",
     "evalue": "No common columns to perform merge on",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMergeError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e555c6ff978c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersect1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# would yield an error because there are no matching column names to merge on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lr/anaconda2/lib/python2.7/site-packages/pandas/tools/merge.pyc\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator)\u001b[0m\n\u001b[1;32m     56\u001b[0m                          \u001b[0mright_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright_on\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mleft_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                          \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                          copy=copy, indicator=indicator)\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lr/anaconda2/lib/python2.7/site-packages/pandas/tools/merge.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUserWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_specification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;31m# note this function has side effects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lr/anaconda2/lib/python2.7/site-packages/pandas/tools/merge.pyc\u001b[0m in \u001b[0;36m_validate_specification\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    810\u001b[0m                     self.right.columns)\n\u001b[1;32m    811\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommon_cols\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mMergeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No common columns to perform merge on'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    813\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcommon_cols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m                     raise MergeError(\"Data columns not unique: %s\"\n",
      "\u001b[0;31mMergeError\u001b[0m: No common columns to perform merge on"
     ]
    }
   ],
   "source": [
    "print np.intersect1d(df1.columns, df4.columns)\n",
    "\n",
    "pd.merge(df1, df4)\n",
    "# would yield an error because there are no matching column names to merge on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a' 'b']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data1</th>\n",
       "      <th>key</th>\n",
       "      <th>data4</th>\n",
       "      <th>rkey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93</td>\n",
       "      <td>b</td>\n",
       "      <td>91</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54</td>\n",
       "      <td>b</td>\n",
       "      <td>91</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64</td>\n",
       "      <td>b</td>\n",
       "      <td>91</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98</td>\n",
       "      <td>a</td>\n",
       "      <td>71</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72</td>\n",
       "      <td>a</td>\n",
       "      <td>71</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>92</td>\n",
       "      <td>a</td>\n",
       "      <td>71</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data1 key  data4 rkey\n",
       "0     93   b     91    b\n",
       "1     54   b     91    b\n",
       "2     64   b     91    b\n",
       "3     98   a     71    a\n",
       "4     72   a     71    a\n",
       "5     92   a     71    a"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Specifying which columns to merge on (if keys have different names in datasets)\n",
    "\n",
    "print np.intersect1d(df1.key, df4.rkey)\n",
    "\n",
    "pd.merge(df1, df4, left_on='key', right_on='rkey')\n",
    "# still an inner join!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['a', 'c', 'b', 'd', 'g', 'f'])\n",
      "['a' 'b' 'c' 'd' 'f' 'g']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data1</th>\n",
       "      <th>key</th>\n",
       "      <th>data2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93.0</td>\n",
       "      <td>b</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.0</td>\n",
       "      <td>b</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64.0</td>\n",
       "      <td>b</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98.0</td>\n",
       "      <td>a</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72.0</td>\n",
       "      <td>a</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>92.0</td>\n",
       "      <td>a</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23.0</td>\n",
       "      <td>c</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>g</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data1 key  data2\n",
       "0   93.0   b   14.0\n",
       "1   54.0   b   14.0\n",
       "2   64.0   b   14.0\n",
       "3   98.0   a   62.0\n",
       "4   72.0   a   62.0\n",
       "5   92.0   a   62.0\n",
       "6   23.0   c    NaN\n",
       "7    NaN   d   40.0\n",
       "8    NaN   f   52.0\n",
       "9    NaN   g   74.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Specifying which type of join: outer\n",
    "print set(df1.key.tolist() + df2.key.tolist())\n",
    "print np.union1d(df1.key, df2.key)\n",
    "\n",
    "\n",
    "pd.merge(df1, df2, how='outer')\n",
    "# the merged dataset will have a union of the keys, imputing NaNs where values aren't found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b' 'a' 'c']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data1</th>\n",
       "      <th>key</th>\n",
       "      <th>data2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93</td>\n",
       "      <td>b</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54</td>\n",
       "      <td>b</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98</td>\n",
       "      <td>a</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>c</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72</td>\n",
       "      <td>a</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>92</td>\n",
       "      <td>a</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>64</td>\n",
       "      <td>b</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data1 key  data2\n",
       "0     93   b   14.0\n",
       "1     54   b   14.0\n",
       "2     98   a   62.0\n",
       "3     23   c    NaN\n",
       "4     72   a   62.0\n",
       "5     92   a   62.0\n",
       "6     64   b   14.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.1 Try out a left join\n",
    "print df1.key.unique()\n",
    "pd.merge(df1, df2, how='left')\n",
    "\n",
    "# value 'c' is absent in df2, so there will be a NaN in column data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   data1 key   col_new\n",
      "0     93   b -1.680196\n",
      "1     54   b  0.004271\n",
      "2     98   a  0.517509\n",
      "3     23   c  1.041373\n",
      "4     72   a  1.534074\n",
      "5     92   a  1.080713\n",
      "6     64   b  1.005952\n",
      "\n",
      "\n",
      "   data2 key   col_new\n",
      "0     62   a -0.730144\n",
      "1     14   b  0.163369\n",
      "2     40   d  0.146430\n",
      "3     52   f  1.533043\n",
      "4     74   g  0.545806 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add a column with the same name to df1 and df2\n",
    "df1['col_new'] = np.random.randn(7)\n",
    "df2['col_new'] = np.random.randn(5)\n",
    "\n",
    "print df1\n",
    "print '\\n\\n', df2, '\\n\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data1</th>\n",
       "      <th>key</th>\n",
       "      <th>col_new_x</th>\n",
       "      <th>data2</th>\n",
       "      <th>col_new_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93.0</td>\n",
       "      <td>b</td>\n",
       "      <td>-1.680196</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.163369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.0</td>\n",
       "      <td>b</td>\n",
       "      <td>0.004271</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.163369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64.0</td>\n",
       "      <td>b</td>\n",
       "      <td>1.005952</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.163369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98.0</td>\n",
       "      <td>a</td>\n",
       "      <td>0.517509</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-0.730144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72.0</td>\n",
       "      <td>a</td>\n",
       "      <td>1.534074</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-0.730144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>92.0</td>\n",
       "      <td>a</td>\n",
       "      <td>1.080713</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-0.730144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23.0</td>\n",
       "      <td>c</td>\n",
       "      <td>1.041373</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.146430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.533043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.545806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data1 key  col_new_x  data2  col_new_y\n",
       "0   93.0   b  -1.680196   14.0   0.163369\n",
       "1   54.0   b   0.004271   14.0   0.163369\n",
       "2   64.0   b   1.005952   14.0   0.163369\n",
       "3   98.0   a   0.517509   62.0  -0.730144\n",
       "4   72.0   a   1.534074   62.0  -0.730144\n",
       "5   92.0   a   1.080713   62.0  -0.730144\n",
       "6   23.0   c   1.041373    NaN        NaN\n",
       "7    NaN   d        NaN   40.0   0.146430\n",
       "8    NaN   f        NaN   52.0   1.533043\n",
       "9    NaN   g        NaN   74.0   0.545806"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df1, df2, on='key', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   data1 key  col_new_df1  data2  col_new_df2\n",
      "0     93   b    -1.680196     14     0.163369\n",
      "1     54   b     0.004271     14     0.163369\n",
      "2     64   b     1.005952     14     0.163369\n",
      "3     98   a     0.517509     62    -0.730144\n",
      "4     72   a     1.534074     62    -0.730144\n",
      "5     92   a     1.080713     62    -0.730144\n"
     ]
    }
   ],
   "source": [
    "# Specifying suffixes to identify columns with the same name\n",
    "print pd.merge(df1, df2, on='key', suffixes=['_df1', '_df2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   data1 key   col_new key2\n",
      "0     93   b -1.680196    x\n",
      "1     54   b  0.004271    y\n",
      "2     98   a  0.517509    x\n",
      "3     23   c  1.041373    y\n",
      "4     72   a  1.534074    x\n",
      "5     92   a  1.080713    y\n",
      "6     64   b  1.005952    z\n",
      "\n",
      "\n",
      "   data2 key   col_new key2\n",
      "0     62   a -0.730144    x\n",
      "1     14   b  0.163369    y\n",
      "2     40   d  0.146430    x\n",
      "3     52   f  1.533043    y\n",
      "4     74   g  0.545806    z \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1['key2'] = list('xy' * 3 + 'z')\n",
    "df2['key2'] = list('xy' * 2 + 'z')\n",
    "print df1\n",
    "print '\\n\\n', df2, '\\n\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('b', 'x'), ('b', 'y'), ('a', 'x'), ('c', 'y'), ('a', 'x'), ('a', 'y'), ('b', 'z')]\n",
      "[('a', 'x'), ('b', 'y'), ('d', 'x'), ('f', 'y'), ('g', 'z')]\n"
     ]
    }
   ],
   "source": [
    "print zip(df1.key, df1.key2)\n",
    "print zip(df2.key, df2.key2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data1</th>\n",
       "      <th>key</th>\n",
       "      <th>col_new_1</th>\n",
       "      <th>key2</th>\n",
       "      <th>data2</th>\n",
       "      <th>col_new_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54</td>\n",
       "      <td>b</td>\n",
       "      <td>0.004271</td>\n",
       "      <td>y</td>\n",
       "      <td>14</td>\n",
       "      <td>0.163369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98</td>\n",
       "      <td>a</td>\n",
       "      <td>0.517509</td>\n",
       "      <td>x</td>\n",
       "      <td>62</td>\n",
       "      <td>-0.730144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72</td>\n",
       "      <td>a</td>\n",
       "      <td>1.534074</td>\n",
       "      <td>x</td>\n",
       "      <td>62</td>\n",
       "      <td>-0.730144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data1 key  col_new_1 key2  data2  col_new_2\n",
       "0     54   b   0.004271    y     14   0.163369\n",
       "1     98   a   0.517509    x     62  -0.730144\n",
       "2     72   a   1.534074    x     62  -0.730144"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df1, df2, on=['key', 'key2'], suffixes=('_1', '_2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set lkey to be the index of df3\n",
    "\n",
    "df3.set_index('lkey', inplace=True)\n",
    "print df3\n",
    "\n",
    "# Note: Do this only once. Re-running set_index will produce errors. You'll have to reset index before you can set it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We specify that for the left df we will use the column called 'key' and for the right df, we will use its index to merge\n",
    "pd.merge(df2, df3, how='left', left_on='key', right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Multiple DataFrame at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df0 = DataFrame({'key': ['a', 'b', 'c', 'd', 'e'], 'data0': np.random.randint(0, 100, 5)})\n",
    "df1 = DataFrame({'key': ['b', 'b', 'a', 'c', 'a', 'a', 'b'], 'data1': np.random.randint(0, 100, 7)})\n",
    "df2 = DataFrame({'key': ['a', 'b', 'd', 'f', 'g'], 'data2': np.random.randint(0, 100, 5)})\n",
    "df3 = DataFrame({'key': ['b', 'x', 'a', 'c', 'a', 'a', 'b'], 'data3': np.random.randint(0, 100, 7)})\n",
    "df4 = DataFrame({'key': ['y', 'b', 'd', 'f', 'a'], 'data4': np.random.randint(0, 100, 5)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data2</th>\n",
       "      <th>key</th>\n",
       "      <th>data0</th>\n",
       "      <th>data1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92</td>\n",
       "      <td>a</td>\n",
       "      <td>24</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92</td>\n",
       "      <td>a</td>\n",
       "      <td>24</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92</td>\n",
       "      <td>a</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>b</td>\n",
       "      <td>94</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>b</td>\n",
       "      <td>94</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>33</td>\n",
       "      <td>b</td>\n",
       "      <td>94</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data2 key  data0  data1\n",
       "0     92   a     24     39\n",
       "1     92   a     24     32\n",
       "2     92   a     24     30\n",
       "3     33   b     94     14\n",
       "4     33   b     94     16\n",
       "5     33   b     94     66"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option 1 : Nesting\n",
    "pd.merge(df2, pd.merge(df0, df1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce(lambda x, y: x + y, range(1, 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data0</th>\n",
       "      <th>key</th>\n",
       "      <th>data1</th>\n",
       "      <th>data2</th>\n",
       "      <th>data3</th>\n",
       "      <th>data4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>a</td>\n",
       "      <td>39.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>a</td>\n",
       "      <td>39.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>a</td>\n",
       "      <td>39.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>a</td>\n",
       "      <td>32.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>a</td>\n",
       "      <td>32.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24</td>\n",
       "      <td>a</td>\n",
       "      <td>32.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>24</td>\n",
       "      <td>a</td>\n",
       "      <td>30.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24</td>\n",
       "      <td>a</td>\n",
       "      <td>30.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>24</td>\n",
       "      <td>a</td>\n",
       "      <td>30.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>94</td>\n",
       "      <td>b</td>\n",
       "      <td>14.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>94</td>\n",
       "      <td>b</td>\n",
       "      <td>14.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>94</td>\n",
       "      <td>b</td>\n",
       "      <td>16.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>94</td>\n",
       "      <td>b</td>\n",
       "      <td>16.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>94</td>\n",
       "      <td>b</td>\n",
       "      <td>66.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>94</td>\n",
       "      <td>b</td>\n",
       "      <td>66.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>43</td>\n",
       "      <td>c</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>40</td>\n",
       "      <td>d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    data0 key  data1  data2  data3  data4\n",
       "0      24   a   39.0   92.0   76.0   81.0\n",
       "1      24   a   39.0   92.0   95.0   81.0\n",
       "2      24   a   39.0   92.0   77.0   81.0\n",
       "3      24   a   32.0   92.0   76.0   81.0\n",
       "4      24   a   32.0   92.0   95.0   81.0\n",
       "5      24   a   32.0   92.0   77.0   81.0\n",
       "6      24   a   30.0   92.0   76.0   81.0\n",
       "7      24   a   30.0   92.0   95.0   81.0\n",
       "8      24   a   30.0   92.0   77.0   81.0\n",
       "9      94   b   14.0   33.0   61.0   19.0\n",
       "10     94   b   14.0   33.0   21.0   19.0\n",
       "11     94   b   16.0   33.0   61.0   19.0\n",
       "12     94   b   16.0   33.0   21.0   19.0\n",
       "13     94   b   66.0   33.0   61.0   19.0\n",
       "14     94   b   66.0   33.0   21.0   19.0\n",
       "15     43   c    0.0    NaN   56.0    NaN\n",
       "16     40   d    NaN   52.0    NaN   82.0\n",
       "17      3   e    NaN    NaN    NaN    NaN"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce(lambda x, y: pd.merge(x, y, how='left'), [df0, df1, df2, df3, df4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<big>Merge - Pandas function <br>\n",
    "JOIN - DataFrame Method (used to join multiple series/dataframe together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataFrame.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data0</th>\n",
       "      <th>data1</th>\n",
       "      <th>data2</th>\n",
       "      <th>data3</th>\n",
       "      <th>data4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>24.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>24.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>24.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>24.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>24.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>24.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>24.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>24.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>24.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>94.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>94.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>94.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>94.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>94.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>94.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     data0  data1  data2  data3  data4\n",
       "key                                   \n",
       "a     24.0   39.0   92.0   76.0   81.0\n",
       "a     24.0   39.0   92.0   95.0   81.0\n",
       "a     24.0   39.0   92.0   77.0   81.0\n",
       "a     24.0   32.0   92.0   76.0   81.0\n",
       "a     24.0   32.0   92.0   95.0   81.0\n",
       "a     24.0   32.0   92.0   77.0   81.0\n",
       "a     24.0   30.0   92.0   76.0   81.0\n",
       "a     24.0   30.0   92.0   95.0   81.0\n",
       "a     24.0   30.0   92.0   77.0   81.0\n",
       "b     94.0   14.0   33.0   61.0   19.0\n",
       "b     94.0   14.0   33.0   21.0   19.0\n",
       "b     94.0   16.0   33.0   61.0   19.0\n",
       "b     94.0   16.0   33.0   21.0   19.0\n",
       "b     94.0   66.0   33.0   61.0   19.0\n",
       "b     94.0   66.0   33.0   21.0   19.0\n",
       "c     43.0    0.0    NaN   56.0    NaN\n",
       "d     40.0    NaN   52.0    NaN   82.0\n",
       "e      3.0    NaN    NaN    NaN    NaN\n",
       "f      NaN    NaN   74.0    NaN    7.0\n",
       "g      NaN    NaN   89.0    NaN    NaN\n",
       "x      NaN    NaN    NaN   70.0    NaN\n",
       "y      NaN    NaN    NaN    NaN   51.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %timeit \n",
    "df0.set_index('key').join(map(lambda df: df.set_index('key'), [df1, df2, df3, df4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print type(pd.merge)\n",
    "print type(DataFrame.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataFrame.join?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.2 The `.join()` method\n",
    "\n",
    ".join is a convenient **DataFrame method** for combining many DataFrames objects with the same or similar indexes but non-overlapping columns into a single result DataFrame.\n",
    "\n",
    "By default, the `join` method performs a _left join_ on the join keys.\n",
    "\n",
    "For simple **index-on-index merges** we can pass a list of DataFrames to `join.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = DataFrame(np.random.randint(0, 50, 32).reshape(8, 4), columns=list('WXYZ'), index=list('abcdefgh'))\n",
    "\n",
    "df1 = df.ix[2:, ['W', 'X']]\n",
    "df2 = df.ix[:5, ['Y', 'Z']]\n",
    "\n",
    "print df1, '\\n\\n', df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Default actions is a left join on the indexes\n",
    "df1.join(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit df1.join(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.merge(df1, df2, how='left', right_index=True, left_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit pd.merge(df1, df2, how='left', right_index=True, left_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can alter the nature of the join by passing how=\n",
    "print df1.join(df2, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a couple more DFs with the same index\n",
    "df3 = df.ix[0:3, ['X', 'Z']]\n",
    "df3.columns = ['P', 'Q']\n",
    "\n",
    "df4 = df.ix[4:6, ['W']]\n",
    "df4.columns = ['R']\n",
    "\n",
    "print df3, \"\\n\\n\", df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print df1, '\\n\\n', df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Merging multiple DFs with the same index by passing a list of names to .join\n",
    "print df1.join([df2, df3, df4]).fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2.join([df1, df3, df4], how='outer').fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "<big>Task 1.</big>\n",
    "\n",
    "Use join on these.\n",
    "\n",
    "\n",
    "```python\n",
    "df_1 = titanic[['Name', 'Age', 'Sex']]\n",
    "df_2 = titanic[['Name', 'Pclass', 'Fare']]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "<big>Task 2. <br><br>\n",
    "\n",
    "Define a function called JOINER which accepts any number of dataframes and joins them. <br>\n",
    "Your function must not fail (no errors can be produced) under any circumstances.\n",
    "\n",
    "</big>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_titanic = pd.read_csv('train.csv')\n",
    "df_1 = df_titanic[['Name', 'Age', 'Sex']]\n",
    "df_2 = df_titanic[['Name', 'Pclass', 'Fare']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Braund, Mr. Owen Harris</th>\n",
       "      <td>22.0</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cumings, Mrs. John Bradley (Florence Briggs Thayer)</th>\n",
       "      <td>38.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Heikkinen, Miss. Laina</th>\n",
       "      <td>26.0</td>\n",
       "      <td>female</td>\n",
       "      <td>3</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Futrelle, Mrs. Jacques Heath (Lily May Peel)</th>\n",
       "      <td>35.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Allen, Mr. William Henry</th>\n",
       "      <td>35.0</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Age     Sex  Pclass  \\\n",
       "Name                                                                       \n",
       "Braund, Mr. Owen Harris                             22.0    male       3   \n",
       "Cumings, Mrs. John Bradley (Florence Briggs Tha...  38.0  female       1   \n",
       "Heikkinen, Miss. Laina                              26.0  female       3   \n",
       "Futrelle, Mrs. Jacques Heath (Lily May Peel)        35.0  female       1   \n",
       "Allen, Mr. William Henry                            35.0    male       3   \n",
       "\n",
       "                                                       Fare  \n",
       "Name                                                         \n",
       "Braund, Mr. Owen Harris                              7.2500  \n",
       "Cumings, Mrs. John Bradley (Florence Briggs Tha...  71.2833  \n",
       "Heikkinen, Miss. Laina                               7.9250  \n",
       "Futrelle, Mrs. Jacques Heath (Lily May Peel)        53.1000  \n",
       "Allen, Mr. William Henry                             8.0500  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.set_index('Name').join(df_2.set_index('Name'))[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def JOINER(*args, **kwargs):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    joined =[]\n",
    "    col_list = [x.columns.tolist() for x in args]\n",
    "    pk = reduce(lambda x, y: np.intersect1d(x, y), col_list).tolist()\n",
    "    HOW = kwargs['HOW']\n",
    "    \n",
    "    if bool(pk):\n",
    "        list_of_dfs = map(lambda df: df.set_index(pk), args)\n",
    "        joined = list_of_dfs[0].join(list_of_dfs[1:], how=HOW)    \n",
    "    else:\n",
    "        print \"There are no common columns to join.\"\n",
    "            \n",
    "    return joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data0</th>\n",
       "      <th>data1</th>\n",
       "      <th>data2</th>\n",
       "      <th>data3</th>\n",
       "      <th>data4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>24.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>24.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>24.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>24.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>24.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>24.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>24.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>24.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>24.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>94.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>94.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>94.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>94.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>94.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>94.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     data0  data1  data2  data3  data4\n",
       "key                                   \n",
       "a     24.0   39.0   92.0   76.0   81.0\n",
       "a     24.0   39.0   92.0   95.0   81.0\n",
       "a     24.0   39.0   92.0   77.0   81.0\n",
       "a     24.0   32.0   92.0   76.0   81.0\n",
       "a     24.0   32.0   92.0   95.0   81.0\n",
       "a     24.0   32.0   92.0   77.0   81.0\n",
       "a     24.0   30.0   92.0   76.0   81.0\n",
       "a     24.0   30.0   92.0   95.0   81.0\n",
       "a     24.0   30.0   92.0   77.0   81.0\n",
       "b     94.0   14.0   33.0   61.0   19.0\n",
       "b     94.0   14.0   33.0   21.0   19.0\n",
       "b     94.0   16.0   33.0   61.0   19.0\n",
       "b     94.0   16.0   33.0   21.0   19.0\n",
       "b     94.0   66.0   33.0   61.0   19.0\n",
       "b     94.0   66.0   33.0   21.0   19.0\n",
       "c     43.0    0.0    NaN   56.0    NaN\n",
       "d     40.0    NaN   52.0    NaN   82.0\n",
       "e      3.0    NaN    NaN    NaN    NaN\n",
       "f      NaN    NaN   74.0    NaN    7.0\n",
       "g      NaN    NaN   89.0    NaN    NaN\n",
       "x      NaN    NaN    NaN   70.0    NaN\n",
       "y      NaN    NaN    NaN    NaN   51.0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JOINER(df0, df1, df2, df3, df4, HOW='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df0 = DataFrame({'key': list('aaabcde'), 'vals1': np.random.randint(0, 10, 7)})\n",
    "df1 = DataFrame({'key': list('aabbcc'), 'vals2': np.random.randint(0, 10, 6)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>vals1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>d</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>e</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  key  vals1\n",
       "0   a      2\n",
       "1   a      6\n",
       "2   a      0\n",
       "3   b      4\n",
       "4   c      8\n",
       "5   d      3\n",
       "6   e      7"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>vals2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>c</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  key  vals2\n",
       "0   a      6\n",
       "1   a      5\n",
       "2   b      9\n",
       "3   b      0\n",
       "4   c      8\n",
       "5   c      1"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>vals1</th>\n",
       "      <th>vals2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>b</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>b</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>c</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>c</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  key  vals1  vals2\n",
       "0   a      2      6\n",
       "1   a      2      5\n",
       "2   a      6      6\n",
       "3   a      6      5\n",
       "4   a      0      6\n",
       "5   a      0      5\n",
       "6   b      4      9\n",
       "7   b      4      0\n",
       "8   c      8      8\n",
       "9   c      8      1"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df0, df1, on='key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.concat?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.3 Concatenating DataFrames \n",
    "## - (aka binding, stacking, union all)\n",
    "\n",
    "### a. Series objects with no index overlap\n",
    "    * concat with axis=0 (default) will append the Series (~rbind)\n",
    "    * concat with axis=1 will merge the Series to produce a DF (~outer join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a   -0.352807\n",
      "b   -0.761518\n",
      "c   -1.030246\n",
      "x    0.339533\n",
      "Name: chintu, dtype: float64 \n",
      "\n",
      " S2:\n",
      "y   -1.601997\n",
      "c    1.387587\n",
      "d    0.414205\n",
      "e    0.532228\n",
      "f   -1.037770\n",
      "g    0.017787\n",
      "Name: sonu, dtype: float64 \n",
      "\n",
      " S3:\n",
      "c   -0.805904\n",
      "f    1.891518\n",
      "g   -0.137295\n",
      "h   -0.740409\n",
      "i   -0.467219\n",
      "Name: monu, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create toy Series with overlapping indices\n",
    "s1 = Series(np.random.randn(4), index=list('abcx'), name='chintu')\n",
    "s2 = Series(np.random.randn(6), index=list('ycdefg'), name='sonu')\n",
    "s3 = Series(np.random.randn(5), index=list('cfghi'), name='monu')\n",
    "\n",
    "print s1, '\\n\\n S2:\\n', s2, '\\n\\n S3:\\n', s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a   -0.352807\n",
       "b   -0.761518\n",
       "c   -1.030246\n",
       "x    0.339533\n",
       "y   -1.601997\n",
       "c    1.387587\n",
       "d    0.414205\n",
       "e    0.532228\n",
       "f   -1.037770\n",
       "g    0.017787\n",
       "c   -0.805904\n",
       "f    1.891518\n",
       "g   -0.137295\n",
       "h   -0.740409\n",
       "i   -0.467219\n",
       "dtype: float64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Default action is to append the data\n",
    "pd.concat([s1, s2, s3], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     chintu      sonu      monu\n",
      "a -0.352807       NaN       NaN\n",
      "b -0.761518       NaN       NaN\n",
      "c -1.030246  1.387587 -0.805904\n",
      "d       NaN  0.414205       NaN\n",
      "e       NaN  0.532228       NaN\n",
      "f       NaN -1.037770  1.891518\n",
      "g       NaN  0.017787 -0.137295\n",
      "h       NaN       NaN -0.740409\n",
      "i       NaN       NaN -0.467219\n",
      "x  0.339533       NaN       NaN\n",
      "y       NaN -1.601997       NaN\n"
     ]
    }
   ],
   "source": [
    "# concat with axis=1 (non-overlapping index)\n",
    "print pd.concat([s1, s2, s3], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.Series.jo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<big> TASK 3 ||  Write a version of the `concat` function that fails gracefully. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `keys=` option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "chintu  a   -0.352807\n",
       "        b   -0.761518\n",
       "        c   -1.030246\n",
       "        x    0.339533\n",
       "sonu    y   -1.601997\n",
       "        c    1.387587\n",
       "        d    0.414205\n",
       "        e    0.532228\n",
       "        f   -1.037770\n",
       "        g    0.017787\n",
       "monu    c   -0.805904\n",
       "        f    1.891518\n",
       "        g   -0.137295\n",
       "        h   -0.740409\n",
       "        i   -0.467219\n",
       "dtype: float64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Passing keys= creates a hierarchical index when appending (axis=0)\n",
    "pd.concat([s1, s2, s3], axis=0, keys=[s.name for s in [s1, s2, s3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          C         S         M\n",
      "a -0.352807       NaN       NaN\n",
      "b -0.761518       NaN       NaN\n",
      "c -1.030246  1.387587 -0.805904\n",
      "d       NaN  0.414205       NaN\n",
      "e       NaN  0.532228       NaN\n",
      "f       NaN -1.037770  1.891518\n",
      "g       NaN  0.017787 -0.137295\n",
      "h       NaN       NaN -0.740409\n",
      "i       NaN       NaN -0.467219\n",
      "x  0.339533       NaN       NaN\n",
      "y       NaN -1.601997       NaN\n"
     ]
    }
   ],
   "source": [
    "# Passing keys= gives names to columns when using axis=1\n",
    "print pd.concat([s1, s2, s3], axis=1, keys=[s.name[0].upper() for s in [s1, s2, s3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Series objects with overlapping index\n",
    "\n",
    "* If there is an overlap on indexes, we can specify **`join=`** to intersect the data\n",
    "    * Note that the `join=` option takes only `'inner'` and `'outer'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a   -1.668432\n",
      "b   -0.139904\n",
      "c    0.262970\n",
      "d    1.436704\n",
      "e   -0.404103\n",
      "Name: S4, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "s4 = Series(np.random.randn(5), index=list('abcde'), name='S4')\n",
    "print s4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a   -0.352807\n",
       "b   -0.761518\n",
       "c   -1.030246\n",
       "x    0.339533\n",
       "Name: chintu, dtype: float64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     chintu        S4\n",
      "a -0.352807 -1.668432\n",
      "b -0.761518 -0.139904\n",
      "c -1.030246  0.262970\n",
      "d       NaN  1.436704\n",
      "e       NaN -0.404103\n",
      "x  0.339533       NaN\n"
     ]
    }
   ],
   "source": [
    "# concat with overlapping index (default join type is outer)\n",
    "print pd.concat([s1, s4], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     chintu        S4\n",
      "a -0.352807 -1.668432\n",
      "b -0.761518 -0.139904\n",
      "c -1.030246  0.262970\n"
     ]
    }
   ],
   "source": [
    "# if we specify a join type, this will be equivalent to a merge\n",
    "print pd.concat([s1, s4], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. DataFrame objects\n",
    "\n",
    "The same logic extends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          X         Y         Z\n",
      "a  0.596043  0.140270 -0.217888\n",
      "b -0.002343  0.858121  2.146465\n",
      "c -0.571256  0.166585 -0.215421 \n",
      "\n",
      "          X         Z\n",
      "p  0.633566  0.112313\n",
      "q  1.376006 -0.358565\n"
     ]
    }
   ],
   "source": [
    "# Create toy dataframes with non-overlapping indexes\n",
    "df1 = DataFrame(np.random.randn(3, 3), index=list('abc'), columns=list('XYZ')) \n",
    "df2 = DataFrame(np.random.randn(2, 2), index=list('pq'), columns=list('XZ'))\n",
    "print df1, '\\n\\n', df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When axis=0 \n",
      "\n",
      "          X         Y         Z\n",
      "a  0.596043  0.140270 -0.217888\n",
      "b -0.002343  0.858121  2.146465\n",
      "c -0.571256  0.166585 -0.215421\n",
      "p  0.633566       NaN  0.112313\n",
      "q  1.376006       NaN -0.358565\n"
     ]
    }
   ],
   "source": [
    "# No overlapping index\n",
    "print 'When axis=0 \\n'\n",
    "print pd.concat([df1, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " When axis=1 \n",
      "\n",
      "          X         Y         Z         X         Z\n",
      "a  0.596043  0.140270 -0.217888       NaN       NaN\n",
      "b -0.002343  0.858121  2.146465       NaN       NaN\n",
      "c -0.571256  0.166585 -0.215421       NaN       NaN\n",
      "p       NaN       NaN       NaN  0.633566  0.112313\n",
      "q       NaN       NaN       NaN  1.376006 -0.358565\n"
     ]
    }
   ],
   "source": [
    "print '\\n When axis=1 \\n'\n",
    "print pd.concat([df1, df2], axis=1)\n",
    "\n",
    "### NEVER DO THIS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          X         Y         Z\n",
      "a  0.407096  0.591862 -0.293056\n",
      "b -1.602185 -0.049404  1.402603\n",
      "c -0.118487  1.522990 -0.697165 \n",
      "\n",
      "          X         Z\n",
      "a  0.308889  0.679124\n",
      "c -1.147507 -0.148984\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>0.407096</td>\n",
       "      <td>0.591862</td>\n",
       "      <td>-0.293056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>-1.602185</td>\n",
       "      <td>-0.049404</td>\n",
       "      <td>1.402603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>-0.118487</td>\n",
       "      <td>1.522990</td>\n",
       "      <td>-0.697165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>0.308889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.679124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>-1.147507</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.148984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          X         Y         Z\n",
       "a  0.407096  0.591862 -0.293056\n",
       "b -1.602185 -0.049404  1.402603\n",
       "c -0.118487  1.522990 -0.697165\n",
       "a  0.308889       NaN  0.679124\n",
       "c -1.147507       NaN -0.148984"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create toy dataframes with overlapping indexes\n",
    "df1 = DataFrame(np.random.randn(9).reshape(3, 3), index=list('abc'), columns=list('XYZ')) \n",
    "df2 = DataFrame(np.random.randn(4).reshape(2, 2), index=list('ac'), columns=list('XZ'))\n",
    "print df1, '\\n\\n', df2\n",
    "\n",
    "# When axis=0 there will still be \n",
    "pd.concat([df1, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>X</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>0.407096</td>\n",
       "      <td>0.591862</td>\n",
       "      <td>-0.293056</td>\n",
       "      <td>0.308889</td>\n",
       "      <td>0.679124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>-1.602185</td>\n",
       "      <td>-0.049404</td>\n",
       "      <td>1.402603</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>-0.118487</td>\n",
       "      <td>1.522990</td>\n",
       "      <td>-0.697165</td>\n",
       "      <td>-1.147507</td>\n",
       "      <td>-0.148984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          X         Y         Z         X         Z\n",
       "a  0.407096  0.591862 -0.293056  0.308889  0.679124\n",
       "b -1.602185 -0.049404  1.402603       NaN       NaN\n",
       "c -0.118487  1.522990 -0.697165 -1.147507 -0.148984"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Overlapping indexes will be merged\n",
    "pd.concat([df1, df2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">df_1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">df_2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>X</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>0.407096</td>\n",
       "      <td>0.591862</td>\n",
       "      <td>-0.293056</td>\n",
       "      <td>0.308889</td>\n",
       "      <td>0.679124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>-1.602185</td>\n",
       "      <td>-0.049404</td>\n",
       "      <td>1.402603</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>-0.118487</td>\n",
       "      <td>1.522990</td>\n",
       "      <td>-0.697165</td>\n",
       "      <td>-1.147507</td>\n",
       "      <td>-0.148984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       df_1                          df_2          \n",
       "          X         Y         Z         X         Z\n",
       "a  0.407096  0.591862 -0.293056  0.308889  0.679124\n",
       "b -1.602185 -0.049404  1.402603       NaN       NaN\n",
       "c -0.118487  1.522990 -0.697165 -1.147507 -0.148984"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([df1, df2], axis=1, keys=['df_1', 'df_2'])\n",
    "# This will create a hierarchical index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.4 $Reshaping$ using `stack()` and `unstack()`\n",
    "\n",
    "Hierarchical Indexing provides a convenient way to reshape data;\n",
    "    * `stack` pivots the columns into rows\n",
    "    * `unstack` pivots rows into columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            W     X     Y     Z\n",
      "one two                        \n",
      "A   C   -0.12 -0.20  2.16  0.72\n",
      "B   D   -0.39 -0.10  0.31 -0.51\n",
      "A   E   -1.28  0.01 -1.09 -0.11\n",
      "B   F   -1.29  2.19  0.24  1.68\n"
     ]
    }
   ],
   "source": [
    "# Create a toy DF with a Hierarchical Index\n",
    "tuples = zip(list('AB'*2), list('CDEF'))\n",
    "multix = pd.MultiIndex.from_tuples(tuples, names=['one', 'two'])\n",
    "\n",
    "df = DataFrame(np.random.randn(4, 4), index=multix, columns=list('WXYZ')).round(2)\n",
    "print df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<big>\n",
    "Use stack when you want to convert a DataFrame into a Series with a hierarchical index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "one  two   \n",
       "A    C    W   -0.12\n",
       "          X   -0.20\n",
       "          Y    2.16\n",
       "          Z    0.72\n",
       "B    D    W   -0.39\n",
       "          X   -0.10\n",
       "          Y    0.31\n",
       "          Z   -0.51\n",
       "A    E    W   -1.28\n",
       "          X    0.01\n",
       "          Y   -1.09\n",
       "          Z   -0.11\n",
       "B    F    W   -1.29\n",
       "          X    2.19\n",
       "          Y    0.24\n",
       "          Z    1.68\n",
       "dtype: float64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.stack()\n",
    "# 1 column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x  a    17\n",
       "   b    34\n",
       "   c     3\n",
       "y  a    45\n",
       "   b     3\n",
       "   c    15\n",
       "z  a     1\n",
       "   b    45\n",
       "   c    49\n",
       "dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrame(np.random.randint(1,50, 9).reshape(3, 3), \n",
    "          columns=list('abc'), \n",
    "          index=list('xyz')).stack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<big> Unstacked is useful when you have a Series with a Hierarchical Index, to convert it \n",
    "into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex(levels=[[u'A', u'B'], [u'C', u'D', u'E', u'F']],\n",
       "           labels=[[0, 1, 0, 1], [0, 1, 2, 3]],\n",
       "           names=[u'one', u'two'])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "one  two\n",
       "A    C      1\n",
       "B    D      2\n",
       "A    E      3\n",
       "B    F      4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Series([1, 2, 3, 4], index=multix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print type(DataFrame.pivot)\n",
    "print type(pd.pivot_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DataFrame.pivot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.pivot_table?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.5 Converting data from 'long' to 'wide' format using `.pivot()`\n",
    "\n",
    "Usually, for convenience, data in relational DB is stored in the **long format**\n",
    "    * fewer columns, label duplication in keys\n",
    "\n",
    "For certain kinds of analysis, we might prefer to have the data in the **wide format **\n",
    "    * more columns, unique labels in keys\n",
    "\n",
    "The `df.pivot()` method takes the names of columns to be used as row (`index=`) and column indexes (`columns=`) and a column to fill in the data as (`values=`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date item    status\n",
      "0  2000-01-03    A -1.756575\n",
      "1  2000-01-04    B  0.163075\n",
      "2  2000-01-05    C -0.372767\n",
      "3  2000-01-03    D -1.751664\n",
      "4  2000-01-04    A -1.299162\n",
      "5  2000-01-05    B  0.107179\n",
      "6  2000-01-03    C  1.314607\n",
      "7  2000-01-04    D -0.908350\n",
      "8  2000-01-05    A  0.910836\n",
      "9  2000-01-03    B  0.689691\n",
      "10 2000-01-04    C -0.440248\n",
      "11 2000-01-05    D -1.098606\n"
     ]
    }
   ],
   "source": [
    "df = DataFrame({'date': (list(pd.date_range('2000-01-03', '2000-01-05')) * 4),\n",
    "          'item': (list('ABCD'*3)),\n",
    "          'status': (np.random.randn(12))})\n",
    "print df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              status                              \n",
      "item               A         B         C         D\n",
      "date                                              \n",
      "2000-01-03 -1.756575  0.689691  1.314607 -1.751664\n",
      "2000-01-04 -1.299162  0.163075 -0.440248 -0.908350\n",
      "2000-01-05  0.910836  0.107179 -0.372767 -1.098606\n"
     ]
    }
   ],
   "source": [
    "print df.set_index(['date', 'item']).unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item               A         B         C         D\n",
      "date                                              \n",
      "2000-01-03 -1.756575  0.689691  1.314607 -1.751664\n",
      "2000-01-04 -1.299162  0.163075 -0.440248 -0.908350\n",
      "2000-01-05  0.910836  0.107179 -0.372767 -1.098606\n"
     ]
    }
   ],
   "source": [
    "print df.pivot(index='date', columns='item', values='status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit df.set_index(['date', 'item']).unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit df.pivot(index='date', columns='item', values='status')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: Pivot is just a convenient wrapper function that replaces the need to create a hierarchical index using `set_index` and reshaping with `stack`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_p = pd.concat([df, df.assign(status = lambda x: x['status'] * 2)])\n",
    "print df_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print pd.pivot_table(data=df_p, \n",
    "               index='date', \n",
    "               columns='item', \n",
    "               values='status', \n",
    "               aggfunc=np.sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.6 $Transforming$ Data\n",
    "\n",
    "## A. Removing Duplicates\n",
    "\n",
    "* `df.duplicated()` Returns boolean Series denoting duplicate rows, optionally only considering certain columns\n",
    "* `df.drop_duplicates()` Returns DataFrame with duplicate rows removed, optionally only considering certain columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = DataFrame({'C1': list('ABC' * 2),\n",
    "          'C2': [1, 2, 4, 3, 2, 4]})\n",
    "print df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print df.assign(Dups = df.duplicated())\n",
    "# Creates a boolean series to indicate which rows have dups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print df[df.duplicated()]\n",
    "# Retain the rows that are duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print df[-df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print df.drop_duplicates()\n",
    "# retain the first occurrence of each row (drop dups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print df.drop_duplicates(keep='last')\n",
    "# retain the last occurrence of each row (drop dups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print df.drop_duplicates(keep=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To find number of duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic[['Sex', 'Pclass', 'Embarked']].duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> By default, these methods consider all of the columns. To specify a subset for detecting duplicates, use **`df.drop_duplicates(['list-of-columns'])`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Replacing Values in a Categorical Column\n",
    "\n",
    "For adding a column based on the transformed values of an existing column (using a lookup table) involves calling the `.map()` method (for Series) which accepts a `dict` or a `function` and applies it to each value.\n",
    "\n",
    "> Note: `.map()` is a convenient way to perform element-wise transformations and data cleaning operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = DataFrame({'key': list('ABC' * 4),\n",
    "               'val': np.random.randint(30, 80, 12)}); print df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lookup = {\n",
    "    'A': 'Excellent',\n",
    "    'B': 'Satisfactory',\n",
    "    'C': 'Improve'\n",
    "}\n",
    "\n",
    "lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Chain single replacements\n",
    "df['key'].replace('A', 'Excellent').replace('B', 'Satisfactory').replace('C', 'Improve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['key'].replace(lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['key'].map(lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['grade'] = df['key'].map(lookup)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['grade_2'] = df['key'].replace(lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit df.key.replace(lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit df.key.map(lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## C. Replacing Values\n",
    "\n",
    "To substitute certain values in a Series by a target-value, we can use the `.replace()` method,\n",
    "specifying the find/replace (target/replacement) values as a list or a dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s = Series(list('abc' * 3))\n",
    "\n",
    "s[3] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Syntax: `my_series.replace(target-value, replace_by_this)`**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s.replace('a', 'AA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s[::2] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s.replace(np.nan, 'nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s.fillna('nan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Task\n",
    "\n",
    "DataFrame(np.random.randint(0, 5, 25)\n",
    ".reshape(5, 5), columns=list('ABCDE')).astype(str)\n",
    "\n",
    "0: zer\n",
    "1: one\n",
    "2: two\n",
    "3: thr\n",
    "4: fou    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_r = DataFrame(np.random.randint(0, 5, 25).reshape(5, 5), columns=list('ABCDE'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_r.replace([0, 1, 2, 3, 4], ['zer','one', 'two', 'thr', 'four'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lookup = {0: 'zer', \n",
    "          1: 'one', \n",
    "          2: 'two', \n",
    "          3: 'thr', \n",
    "          4: 'fou'}\n",
    "\n",
    "df_r.applymap(lambda x: lookup.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit df_r.replace([0, 1, 2, 3, 4], ['zer','one', 'two', 'thr', 'four'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit df_r.applymap(lambda x: lookup[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.cut?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## D. Binning Numeric Variables to Categoricals\n",
    "\n",
    "The `pd.cut()` and `pd.qcut()` functions are used; they take as arguments the following;\n",
    "\n",
    "* `var`, the continuous variable to discretize\n",
    "* `bins`, specified as a number (equal sized bins will be computed based on min/max) or a list of bin edges\n",
    "* `right=True`, a boolean to include the edge or not\n",
    "* `labels=`, for naming the bins\n",
    "* `precision=`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a list of 20 integers between 1 and 100\n",
    "var = np.random.randint(1, 100, 500)\n",
    "print var[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zip(Series(var)[:10], pd.cut(Series(var), 10)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zip(Series(var)[:10], pd.cut(Series(var), bins=range(0, 101, 20))[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Automatic Binning\n",
    "pd.cut(var, bins=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.cut(var, bins=5).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(pd.cut(var, bins=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zip(var, pd.cut(var, \n",
    "                bins=range(0, 101, 20), \n",
    "                right=False,\n",
    "                labels=['Bin_' + str(x) for x in range(5)]))[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.concat([Series(var[:10], name='Values'), \n",
    "           Series(pd.cut(var, bins=[0, 33,  66, 100], \n",
    "                         labels=['0-33', '34-66', '67-100'])[:10], name='Bins')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.cut(var, 3, labels=['one', 'two', 'three'], retbins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.cut(var, [0, 25, 50, 75, 100]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.cut(var, [0, 25, 50, 75, 100]).value_counts().plot.barh(figsize=(4, 2));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cutting variables drawn from a known distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Series(np.random.exponential(0.5, 10000)).plot.hist(bins=30, figsize=(3 ,3));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.cut(np.random.exponential(0.5, 10000), 15, right=False).value_counts().plot.bar(figsize=(5, 3));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that `.cut(data, bins)` automatically bins values by splitting the range into equal-sized bins.\n",
    "\n",
    "As a result, the distribution is not uniform.\n",
    "\n",
    "This is where `qcut` comes in.\n",
    "\n",
    "#### E. Binning into quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.qcut(np.random.normal(1, 1, 100000), 10).value_counts().plot.bar(figsize=(3, 3));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<big>\n",
    "\n",
    "- `pd.cut` -> same distributions as the underlying data\n",
    "- `pd.qcut` -> uniform distribtion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataFrame.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Series.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F. Random Sampling\n",
    "\n",
    "We can use the `np.random.permutation` function (passing nrows as an argument) for randomly reordering a Series.\n",
    "\n",
    "To select a random sample, create an index and subset the DF using it.\n",
    "* **Without replacement**: slice off the first _k_ rows; where _k_ is the size of the subset you desire\n",
    "* **With replacement**: use `np.random.randint(start, stop, size=)` to draw integers at random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.08</td>\n",
       "      <td>-2.21</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>-1.54</td>\n",
       "      <td>-0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.39</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.23</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.28</td>\n",
       "      <td>1.27</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.56</td>\n",
       "      <td>-0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.38</td>\n",
       "      <td>-1.76</td>\n",
       "      <td>-1.17</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>-1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.73</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.89</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.83</td>\n",
       "      <td>-1.40</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-1.08</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.56</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>0.88</td>\n",
       "      <td>-0.95</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.26</td>\n",
       "      <td>2.29</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.72</td>\n",
       "      <td>-0.85</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      A     B     C     D     E\n",
       "0  0.08 -2.21 -0.51 -1.54 -0.54\n",
       "1 -1.39 -0.51 -0.62  0.11 -0.68\n",
       "2 -0.23 -0.55 -0.42  0.16  0.41\n",
       "3  0.28  1.27  1.59  0.56 -0.04\n",
       "4  2.38 -1.76 -1.17 -0.17 -1.20\n",
       "5 -0.73  0.25  1.89  0.70  1.79\n",
       "6  0.83 -1.40 -0.10 -1.08  0.46\n",
       "7 -0.56 -0.24  0.88 -0.95  0.06\n",
       "8  0.26  2.29 -0.37  0.14 -0.13\n",
       "9  0.14  0.72 -0.85  0.50  1.50"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = DataFrame(np.random.randn(1000, 5), columns=list('ABCDE')).round(2)\n",
    "df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 5)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>1.57</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.59</td>\n",
       "      <td>1.35</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.53</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-1.23</td>\n",
       "      <td>-0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>-1.48</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>-0.21</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-1.97</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.60</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-0.85</td>\n",
       "      <td>-0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>-2.04</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1.61</td>\n",
       "      <td>-0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>-0.57</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.63</td>\n",
       "      <td>-0.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        A     B     C     D     E\n",
       "81   0.01 -0.19 -1.00  0.09 -0.01\n",
       "971 -0.11 -0.56  0.68 -0.23  0.41\n",
       "614  1.57 -0.36  0.15  0.58  0.32\n",
       "130  0.59  1.35  1.67  0.57  1.17\n",
       "505  0.14  0.53 -0.11 -1.23 -0.54\n",
       "803 -1.48 -0.35  0.48  0.98  0.55\n",
       "384 -0.21  0.39 -0.04 -1.97  0.07\n",
       "956  0.18  0.60 -0.19 -0.85 -0.06\n",
       "860 -2.04  0.32  0.42  1.61 -0.69\n",
       "724 -0.57 -0.47  0.54  0.63 -0.11"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_1k = Series(np.random.permutation(1000))\n",
    "df.iloc[s_1k[:10], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>1.57</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.59</td>\n",
       "      <td>1.35</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.53</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-1.23</td>\n",
       "      <td>-0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>-1.48</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>-0.21</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-1.97</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.60</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-0.85</td>\n",
       "      <td>-0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>-2.04</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1.61</td>\n",
       "      <td>-0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>-0.57</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.63</td>\n",
       "      <td>-0.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        A     B     C     D     E\n",
       "81   0.01 -0.19 -1.00  0.09 -0.01\n",
       "971 -0.11 -0.56  0.68 -0.23  0.41\n",
       "614  1.57 -0.36  0.15  0.58  0.32\n",
       "130  0.59  1.35  1.67  0.57  1.17\n",
       "505  0.14  0.53 -0.11 -1.23 -0.54\n",
       "803 -1.48 -0.35  0.48  0.98  0.55\n",
       "384 -0.21  0.39 -0.04 -1.97  0.07\n",
       "956  0.18  0.60 -0.19 -0.85 -0.06\n",
       "860 -2.04  0.32  0.42  1.61 -0.69\n",
       "724 -0.57 -0.47  0.54  0.63 -0.11"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[s_1k[:int(len(df) * 0.01)], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -  Without Replacement using `permutation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a randomized index equal to the length of the DF\n",
    "sample = np.random.permutation(len(df))\n",
    "\n",
    "# Subset it to retain only the desired number of cases\n",
    "train = sample[:np.around(len(df) * 0.7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Index the DF using this\n",
    "df_TRAIN = df.loc[train]\n",
    "print len(train), '\\n', df_TRAIN.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## - With Replacement using `randint`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Series(np.random.randint(1, 1000, 500)).value_counts()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# WITH REPLACEMENT\n",
    "repl = np.random.randint(0, 1000, 700)\n",
    "Series(repl).value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sample with duplicate rows\n",
    "# df.ix[repl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.ix[repl].duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling using `.sample()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    700\n",
       "dtype: int64"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WIthout replacement\n",
    "df.sample(n=700, replace=False).duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    495\n",
       "True     205\n",
       "dtype: int64"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WIth replacement\n",
    "df.sample(frac=0.7, replace=True).duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## G. Create Dummies for a Categorical Variable\n",
    "Create a (n x k) matrix of binary variables from a categorical variable of length n with k levels.\n",
    "\n",
    "`pd.get_dummies(var)` does this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_G = DataFrame({'key': list('bbacccb'),\n",
    "                 'val': np.random.randn(7)})\n",
    "print df_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print (DataFrame({'key': df_G['key']}).assign(dummy_a = lambda x: [int(i=='a') for i in x['key']],\n",
    "                                              dummy_b = lambda x: [int(i=='b') for i in x['key']],\n",
    "\n",
    "                                              dummy_c = lambda x: [int(i=='c') for i in x['key']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# automatic\n",
    "# one categorical column -> dataframe of dummies\n",
    "\n",
    "print pd.get_dummies(df_G['key'], prefix='dummy').drop('dummy_c', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "int(True), int(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create and merge dummies in the same DF\n",
    "(df_G\n",
    " .join(pd.get_dummies(df_G['key'], prefix='dummy'))\n",
    " .drop(['key', 'dummy_c'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a categorical variable from a numeric and then compute dummies\n",
    "df_G.val = np.random.rand(7)\n",
    "df_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zip(df_G['val'], pd.cut(df_G['val'], 3, labels=list('XYZ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.get_dummies(pd.cut(df_G['val'], 3, labels=list('XYZ')), prefix='dummy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(np.random.randint(1, 100, 10**4))\n",
    "len(np.random.randint(10**3, 10**5, 10**4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<big> Task 1\n",
    "\n",
    "- Create a dataframe with 2 variables called 'Age' and 'Income'. \n",
    "- Fill these with random integers between (1, 100) and (10k to 100k) for 'Income'.  Use 10k rows.\n",
    "- Use cut to bin Age into 5 bins.\n",
    "- Use qcut to bin Income in to 10 bins. \n",
    "- Assign meaningful labels to each.\n",
    "- Convert both these cut variables into Dummies.\n",
    "- Report the mean and sum of each dummy variable.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_x = DataFrame({'Age': np.random.randint(1, 100, 6543),\n",
    "                 'Income': np.random.randint(10000, 100000, 6543)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_x = df_x.assign(Age_binned = lambda x: pd.cut(x['Age'], 5, labels=['AgeGrp_' + str(i + 1) for i in range(5)]),\n",
    "                   Inc_binned = lambda x: pd.cut(x['Income'], 10, labels=['IncGrp_' + str(i + 1) for i in range(10)])\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DataFrame({'Age_Sum': pd.get_dummies(df_x['Age_binned']).sum(), \n",
    " 'Age_Mean': pd.get_dummies(df_x['Age_binned']).mean()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DataFrame({'Inc_Sum': pd.get_dummies(df_x['Inc_binned']).sum(), \n",
    " 'Inc_Mean': pd.get_dummies(df_x['Inc_binned']).mean()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NUMERIC to CATEGORICAL (via binning) to DUMMIES (via dummification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_G.join(pd.get_dummies(pd.cut(df_G['val'], 3, labels=list('XYZ')), \n",
    "                         prefix='dummy')).drop('key', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read: **DUMMY VARIABLE TRAP**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H. String Methods\n",
    "\n",
    "These include methods applied to string objects that \n",
    "* split a string by given delimiter - `.split()`\n",
    "* trim whitespace - `.strip()`\n",
    "* concatenate strings - `.join()`\n",
    "* detect substrings - `.find()` and `.index()`\n",
    "* count occurrences - `.count()`\n",
    "* find and replace - `.replace()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = 'ready, set ,   go '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Trimming whitespace\n",
    "[x.strip() for x in s.split(',')]\n",
    "\n",
    "# Also see rstrip, lstrip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# String Splitting\n",
    "' '.join([x.strip() for x in s.split(',')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'_#_'.join(list('abcde'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Concatenating Strings\n",
    "pieces = list('abcde')\n",
    "print '::'.join(pieces)\n",
    "print '--'.join(pieces)\n",
    "print ' '.join(pieces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Does a Substring belong to a string\n",
    "print 'steady' in s\n",
    "print 'set' in s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Locate a substring\n",
    "s.index('go')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s[15:17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence = 'the sun rises in the east'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentence.index('east') == sentence.find('east')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print sentence.index('west')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print sentence.find('west')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentence[21:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentence.find('ris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentence.count('t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Locate a substring\n",
    "s.find(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Count occurrences\n",
    "s.count(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentence.endswith('east')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s2 = 'the quick brown fox jumps over the lazy dog'\n",
    "s2.find('fox')\n",
    "\n",
    "print 'lazy' in s2\n",
    "\n",
    "print s2.endswith('dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s.startswith('ready')\n",
    "# similarly .endswith()a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<big>\n",
    "\n",
    "These string functions become very important in conjunction with the `map()` method when we're rying to clean text data.\n",
    "\n",
    "\n",
    "-----------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Regular Expressions\n",
    "\n",
    "https://docs.python.org/2/library/re.html\n",
    "\n",
    "A Regex is a sequence of characters that define a search pattern used in find-and-replace actions.\n",
    "\n",
    "Example: The regex\n",
    "* `\\s+` describes one or more whitespaces\n",
    "* `(?<=\\.) {2,}(?=[A-Z])` matches at least two spaces occurring after period (.) and before an upper case letter\n",
    "\n",
    "Note:\n",
    "* Before a regex is applied to a string, it must be _compiled_ to create a reusable regex object.\n",
    "* The object's methods can then be called on a string.\n",
    "* These include: \n",
    "    * **`split`**, \n",
    "    * **`findall`** (returns all matches), \n",
    "    * **`match`** (checks only the beginning of the string), \n",
    "    * **`search`** (returns the first occurrence)\n",
    "    * **`sub`** (returns a new string with occurrences of the pattern replaced with the supplied string)\n",
    "\n",
    "Syntax:\n",
    "1. `import re`\n",
    "2. `r_obj = re.compile('my-regex')`\n",
    "3. `r_obj.method(my-text)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Ch. 8 Plotting and Visualization\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1. matplotlib basics\n",
    "\n",
    "\n",
    "http://matplotlib.org/\n",
    "\n",
    "* Run **`import matplotlib.pyplot as plt`**\n",
    "* Create a figure object using **`plt.figure`**\n",
    "* Add subplots to it using **`add_subplot`**\n",
    "    * This creates **AxesSubplot** objects on which you can place plots\n",
    "* Use a plotting command like **`plt.plot`** and matplotlib will place your plot on this canvas\n",
    "\n",
    "\n",
    "### 1.1 Figure, Subplots, AxisSubplot objects and your plot\n",
    "\n",
    "#### Create a 2x2 figure and add three plots to it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# convention\n",
    "\n",
    "%pylab inline\n",
    "# brings the plot to jupyter from the console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create an empty figure\n",
    "fig = plt.figure(figsize=(6, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run plt.figure? to check out figure options like size, dpi, color\n",
    "\n",
    "axsp1 = fig.add_subplot(2, 2, 1)\n",
    "# There will be 2 x 2 subplots on the figure and axsp1 will put your plot on subplot 1\n",
    "\n",
    "axsp2 = fig.add_subplot(2, 2, 2)\n",
    "axsp3 = fig.add_subplot(2, 2, 3)\n",
    "# Now, we have three AxesSubplot objects on our figure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First plot: timeseries\n",
    "axsp1.plot(np.random.randn(40).cumsum(), 'r--')\n",
    "\n",
    "# Second plot: histogram\n",
    "axsp2.hist(np.random.randn(400), bins=10, color='b', alpha=0.3)\n",
    "\n",
    "# Third plot: scatterplot\n",
    "axsp3.scatter(np.arange(30), 4 * np.arange(30) + 6 * np.random.randn(30))\n",
    "# Note: if you make changes to the AxisSubplot object, you'll have to re-run the commands above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Shorthand to achieve the same effect\n",
    "\n",
    "* Create a grid figure using **`plt.subplots`**\n",
    "    * Syntax: `fig, axes = plt.subplots(rows, cols, figsize = (width, height), sharex=False, sharey=False)`\n",
    "    \n",
    "* It returns an array of **AxisSubplot** objects \n",
    "* Reference them using basic indexing (Saves typing!)\n",
    "\n",
    "`plt.subplots` has some interesting options such as `sharex/sharey` which are useful when comparing data on the same scale\n",
    "\n",
    "Run `plt.subplots?` for more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(8, 4))\n",
    "\n",
    "axes[1, 1].plot(np.random.randn(50).cumsum(), 'g-_')\n",
    "axes[2, 1].scatter(np.arange(30), np.log10(np.arange(30)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "> NOTE:\n",
    "`subplots.adjust` is a Figure method that can be used to adjust figure parameters like spacing between subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig1, axes1 = plt.subplots(2, 2, figsize=(12, 4), sharex=True, sharey=True)\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        axes1[i, j].hist(np.random.randn(500), bins=15, alpha=0.4, color='c')\n",
    "\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.2)        \n",
    "# comment out the plt.subplots line and re-run. See what happens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1.3 Plot Formatting\n",
    "\n",
    "#### a. Color, Linestyle and Markers\n",
    "\n",
    "The `plot` function takes `x, y` and optionally an abbreviation to specify `marker, color, and style`\n",
    "\n",
    "Example: Abbreviations work as `color-marker-style`, so `'g--'` means color = 'green' and linestyle = '--'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(np.sin(np.arange(50)), 'b*-');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### b. Ticks, Labels, Legends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(8, 5))\n",
    "ax1 = f.add_subplot(1, 1, 1)\n",
    "ax1.plot(4 + 6 * np.sin(np.arange(50)), 'g*-');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ticks\n",
    "ax1.set_xticks([5, 15, 25, 35, 45])\n",
    "\n",
    "# Chart title\n",
    "ax1.set_title('This is a Sine Curve')\n",
    "\n",
    "# Axis Label\n",
    "ax1.set_xlabel('X')\n",
    "ax1.set_ylabel('4 + 6 * sin(X)')\n",
    "\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add more plots\n",
    "ax1.plot(np.log(np.arange(50)), 'r', label='log(x)')\n",
    "ax1.plot(np.sqrt(np.arange(50)), 'b*--', label='sqrt(x)')\n",
    "\n",
    "# Add a legend\n",
    "ax1.legend(loc='best')\n",
    "\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Saving plots to file\n",
    "\n",
    "**Syntax**: `plt.savefig('file-path.extension', dpi=)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Series.plot\n",
    "DataFrame.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataFrame.plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2. Plotting in `pandas`\n",
    "\n",
    "* There are high level plotting methods that take advantage of the fact that data are organized in DataFrames (have index, colnames)\n",
    "* Both `Series` and `DataFrame` objects have a `pandas.plot` method for making different plot types\n",
    "* Other parameters that can be passed to `pandas.plot` are:\n",
    "    * `xticks, xlim, yticks, ylim`\n",
    "    * `label`\n",
    "    * `style` (as an abbreviation,) and `alpha`\n",
    "    * `grid=True`\n",
    "    * `rot` (rotate tick labels by and angle 0-360)\n",
    "    * `use_index` (use index for tick labels)\n",
    "    * `subplots=False`\n",
    "\n",
    "### 2.1 One variable (plotting a Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = Series(np.random.randn(100).cumsum())\n",
    "s.name = 'random_time_series'\n",
    "s.plot();\n",
    "# Default is a line chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<big> \n",
    "\n",
    "Two ways of specifying the kind of plot to make\n",
    "\n",
    "- `X.plot(kind=<plottype>`\n",
    "- `X.plot.<plottype>`\n",
    "\n",
    "Where X is a Series or a DataFrame\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s.plot(legend=True, title='My First Pandas Plot',\n",
    "       xlim=(0, 100), ylim=(-20, 20), style='g');\n",
    "\n",
    "s2 = s * 1.3\n",
    "s2.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Chart with options\n",
    "s.plot(grid=True, \n",
    "       legend=True,\n",
    "       label='timeseries',\n",
    "       title='Random Normal Numbers - Cumulative Series',\n",
    "       xlim=(0, 100), \n",
    "       ylim=(-8, 4),\n",
    "       xticks=np.arange(0, 100, 10), \n",
    "       yticks=np.arange(-10, 10, 2),\n",
    "       style='r--', \n",
    "       alpha=0.9,\n",
    "       figsize=(7, 3)\n",
    "      );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# One Variable as a Histogram\n",
    "Series(np.random.randn(10000)).plot(kind='hist', \n",
    "                                    bins=50, \n",
    "                                    color='r', \n",
    "                                    alpha=0.7, \n",
    "                                    title='A histogram');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "s2 = norm.rvs(size=10000, loc=4, scale=2.5)\n",
    "s3 = norm.rvs(size=10000, loc=-2, scale=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Series(s2).plot.hist(bins=50, color='g', alpha=0.8)\n",
    "Series(s3).plot(kind='hist', bins=50, color='b', alpha=0.2)\n",
    "plt.savefig('twoHistograms.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(Series(np.random.randint(0, 10, 25))\n",
    " .value_counts()\n",
    " .sort_index()\n",
    " .plot.bar(title='Bar Chart with Random Integers',\n",
    "          grid=False));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting with Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Embarked'].value_counts().plot.barh(figsize=(3, 3));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Age'].plot.hist(bins=20, figsize=(3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Fare'].plot.hist(figsize=(3, 3), bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Multiple Variables (plotting a DataFrame)\n",
    "\n",
    "We can choose between plotting\n",
    "* All Variables on one plot\n",
    "* Each variable on a separate plot\n",
    "\n",
    "In addition to the parameters above, `DataFrame.plot` also takes\n",
    "* `subplots=False` (default is to plot all on the same figure)\n",
    "* `sharex=False, sharey=False`\n",
    "* `figsize`\n",
    "* `title, legend`\n",
    "* `sort_columns`\n",
    "\n",
    "### a. Variables on the same plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = DataFrame(np.random.randn(5000, 5), \n",
    "               index=['Day_' + str(d) for d in range(5000)],\n",
    "               columns=['APL', 'FBK', 'GOOG', 'MCRS', 'TWTR']).cumsum().round(3); df[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Default plot\n",
    "df.plot(figsize=(10, 4));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Each variable on its own plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.plot(figsize=(5, 10), subplots=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.plot(figsize=(5, 10), subplots=True, sharey=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Rainfall in Himachal\n",
    "\n",
    "#### Data from $data.gov.in$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://data.gov.in/node/87154/datastore/export/csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(df['STATE/UT'] == 'HIMACHAL').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.loc[(df['STATE/UT'] == 'HIMACHAL'), 'DISTRICT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(df[df['STATE/UT'] == 'HIMACHAL']\n",
    " .set_index('DISTRICT')\n",
    " .drop('STATE/UT', axis=1)\n",
    " .loc[:, 'JAN':'DEC'] \n",
    " .T\n",
    " .plot(subplots=True, sharey=True, figsize=(8, 24)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap((df[df['STATE/UT'] == 'HIMACHAL']\n",
    " .set_index('DISTRICT')\n",
    " .drop('STATE/UT', axis=1)\n",
    " .loc[:, 'JAN':'DEC'].T).corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(df[df['STATE/UT'] == 'HIMACHAL']\n",
    " .set_index('DISTRICT')\n",
    " .drop('STATE/UT', axis=1)\n",
    " .loc[:, 'JUL']).sort_values().plot.barh(figsize=(3, 6));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2 = (df[df['STATE/UT'] == 'HIMACHAL']\n",
    " .set_index('DISTRICT')\n",
    " .drop('STATE/UT', axis=1)\n",
    " .loc[:, 'JAN':'DEC']).loc[:, 'JUL':'AUG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = range(0, df2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2.plot.scatter(x='JUL', y='AUG', c=x, cmap=\"Spectral\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Barplots\n",
    "\n",
    "This is as simple as passing `kind=bar` or `kind=barh` (for horiz bars) to `pd.plot`\n",
    "\n",
    "#### One Variable (simple barplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 1, figsize=(14, 14))\n",
    "s = Series(np.random.rand(10), index=list('abcdefghij'))\n",
    "\n",
    "s.plot(kind='bar', \n",
    "       ax=axes[0], \n",
    "       color='k', \n",
    "       alpha=0.6)\n",
    "\n",
    "s.plot(kind='barh', \n",
    "       ax=axes[1], \n",
    "       color='k')\n",
    "\n",
    "s.plot(\n",
    "    ax=axes[2], \n",
    "    color='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = DataFrame(np.random.rand(5,5), index=list('ABCDE'), columns=list('PQRST'))\n",
    "print df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.plot(kind='bar', stacked=True, figsize=(10, 8))\n",
    "plt.savefig('stackedBarcharts.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: Functions `value_counts()` and `pd.crosstab()` prove helpful to prepare data for stacked bar charts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Histograms & Density Plots\n",
    "\n",
    "* _Histograms_: Pass `kind='hist'` to `pd.plot()` or use the method `pd.hist()`\n",
    "* _Density Plots_: Use `kind='kde'`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the `.hist()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Series(np.random.randn(1000)).hist(bins=20, alpha=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the `.plot()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Series(np.random.randn(1000)).plot(kind='hist', bins=20, color='Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = Series(np.random.randn(10000))\n",
    "s.plot(kind='kde', color='b') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A bimodal distribution \n",
    "s1 = np.random.normal(0, 1, 2000)\n",
    "s2 = np.random.normal(9, 2, 2000)\n",
    "\n",
    "v = Series(np.concatenate([s1, s2]))\n",
    "\n",
    "v.hist(bins=100, alpha=0.4, color='B', normed=True)\n",
    "v.plot(kind='kde', style='k--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Image(\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/d4/Correlation_examples2.svg/2000px-Correlation_examples2.svg.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# e. Scatter Plots\n",
    "\n",
    "- `.plot(kind='scatter')`\n",
    "- `.scatter()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = DataFrame({'A': np.arange(50),\n",
    "               'B': np.arange(50) + np.random.randn(50),\n",
    "               'C': np.sqrt(np.arange(50)) + np.sin(np.arange(50)) })\n",
    "print df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Two variable Scatterplot\n",
    "plt.scatter(df['B'], df['C'])\n",
    "plt.title('Scatterplot of X and Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.plot(kind='scatter', x='B', y='C', title = 'Scatterplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.plot.scatter(x='B', y='C', title = 'Scatterplot', color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatterplot Matrix\n",
    "\n",
    "A MOST important visual that allows you to see, for numeric variables:\n",
    "\n",
    "- The distribution of each (histograms or kde along the diagonal)\n",
    "- The relationships between variables (as pairwise scatterplots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://data.gov.in/node/87154/datastore/export/csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.scatter_matrix(df.loc[df['STATE/UT'] == 'HIMACHAL', 'JAN':'JUL'], alpha=0.5, figsize=(12, 6))\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.scatter_matrix(df, diagonal='kde', color='k', alpha=0.5, figsize=(12, 6))\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Split - Apply - Combine_\n",
    "\n",
    "## Advanced GroupBy\n",
    "\n",
    "In Data Analysis workflows, operations like `loading, cleaning and merging` are usually following by `summarizations` using some grouping variable(s). This includes _summary statistics_ over variables or groups within variables, within-group _transformations_ (like variable standardization), computing _pivot-tables_ and group analyses.\n",
    "\n",
    "* _Split:_\n",
    "    * A DataFrame can be split up by rows(`axis=0`)/columns(`axis=1`) into **groups**. \n",
    "    * We use `pd.groupby()` to create a groupby object\n",
    "* _Apply:_\n",
    "    * A function is applied to each group.\n",
    "* _Combine:_\n",
    "* The results of applying functions to groups are put together into an object \n",
    "    * data types of returned objects are handled gracefully by pandas\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.groupby('STATE/UT').apply(lambda g: g.loc[:, 'JAN':'DEC'].median()).T.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_rainfall = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"http://i.imgur.com/yjNkiwL.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = DataFrame({'k1': list('abcd' * 25),\n",
    "               'k2': list('xy' * 25 + 'yx' * 25),\n",
    "               'v1': np.random.rand(100),\n",
    "               'v2': np.random.rand(100)}); df[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Syntax\n",
    "\n",
    "`df.groupby('[<col-name(s)>]').apply(<udfs>) or <existing-function>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping by one key \n",
    "\n",
    "**Results in a summarized data frame indexed by levels of the key**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print '\\n', df.groupby('k1').mean()\n",
    "print '\\n', df.groupby('k2').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping by two keys\n",
    "\n",
    "**Results in a summarized data frame with a hierarchical index**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print df.groupby(['k1', 'k2']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grpd = df.groupby(['k1', 'k2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(grpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print grpd['v1'].sum()\n",
    "print\n",
    "print grpd['v2'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grpd.agg?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grpd.agg({'v1': 'mean',\n",
    "          'v2': 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all(grpd['v1'].sum() == grpd['v1'].apply(np.sum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ** GroupBy objects **\n",
    "\n",
    "* `DataFrame.groupby(<key>)` will produce a groupby object\n",
    "* have a `.size()` method, which returns the count of elements in each group.\n",
    "* can be subsetted using column names (or arrays of column names) to select variables for aggregation\n",
    "* have optimized methods for general aggregation operations like - \n",
    "    * `count, sum`\n",
    "    * `mean, median, std, var`\n",
    "    * `first, last`\n",
    "    * `min, max`\n",
    "* methods like `.describe` apply to these objects\n",
    "\n",
    "** By far, the most important GroupBy methods are `.agg() .transform()`, and `.apply()` **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rain_grpby = df_rainfall.groupby('STATE/UT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rain_grpby.size().sort_values(ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "obj = df.groupby(['k1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "obj.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print obj.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groupby objects Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "obj.agg?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Task 1: \n",
    "\n",
    "1. Create a 100x4 DataFrame filled with random numbers (from a normal distribution.)\n",
    "Ensure that there's 2 categorical columns with 5 and 3 categories each.\n",
    "\n",
    "2. Create the groupby object using both keys and find the mean, max, median for each group.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 Column-wise aggregations and UDFs\n",
    "\n",
    "** For simple aggregations (Series or all numeric columns of a DataFrame) we can call methods like `mean` and `sum` **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Summing a Series\n",
    "# Syntax: Select a Series - GroupBy - Apply function\n",
    "df.groupby('k1')['v1'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Summing all Series of a DataFrame\n",
    "# Syntax: Select DF - Groupby - Apply\n",
    "print df.groupby('k2').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** or you can pass the name of a function as a string with the `.agg()` method **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.groupby('k1')['v1'].agg('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print df.groupby('k1').agg('mean').add_prefix('mu_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.concat([df.groupby(df.k1).agg('mean').add_prefix('mu_'),\n",
    "           df.groupby(df.k1).agg('std').add_prefix('sigma_')], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### The `.agg()` method\n",
    "\n",
    "takes as argument the following:\n",
    "* list of function names to be applied to all selected columns\n",
    "* tuples of (colname, function) to be applied to all selected columns\n",
    "* dict of (df.col, function) to be applied to each df.col\n",
    "\n",
    "** 1. Apply >1 functions to selected column(s) by passing names of functions to `agg()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Apply min, mean, max and max to v1 grouped by k1\n",
    "df.groupby('k1').agg(['min', 'mean', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Apply min and max to all numeric columns of df grouped by k2\n",
    "df.groupby('k2')[['v1', 'v2']].agg(['min', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Hierarchical index will be created\n",
    "# We can call .stack on the returned object!\n",
    "\n",
    "df.groupby('k2')[['v1', 'v2']].agg(['min', 'max']).stack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. We can supply names for the columns in the aggregated df\n",
    "\n",
    "to the agg() method, in a list of tuples as `[(colname1, func1), (colname2, func2) ...] `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print df.groupby('k1')[['v1', 'v2']].agg([('smallest', 'min'), ('largest', 'max')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. We can supply df columns and which funcs to apply to each\n",
    "\n",
    "to the agg() method in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Apply max and min to v1; and mean and sum to v2; all grouped by k1\n",
    "print df.groupby('k1').agg({'v1': ['max', 'min'], \n",
    "                            'v2': ['mean', 'sum']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### The `.apply()` method\n",
    "\n",
    "takes as argument the following:\n",
    "* a general or user defined function\n",
    "* any other parameters that the function would take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.groupby('k1').apply?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def topN(data, col, N):\n",
    "    return data.sort_values(by=col, ascending=False).loc[:, col].head(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.groupby('k2').apply(topN, col='v1', N=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.groupby('k1').apply(topN, col='v2', N=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def analyze(df):\n",
    "    return pd.Series({\"nrow\": len(df), \"ncol\": len(df.columns)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Rows and Cols per group\n",
    "print df.groupby(\"k1\").apply(analyze)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "## Time Series Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dates = pd.date_range('1950-01', '2013-03', freq='M'); dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ts = DataFrame(np.random.randn(758, 4), columns=list('ABCD'), index=dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ts['year'] = ts.index.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Aggregating data by year\n",
    "print ts.groupby('year').sum().tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize Trends over time\n",
    "ts.drop('year', axis=1).cumsum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Subsetting data for a decade\n",
    "ts['1980':'1990'].drop('year', axis=1).cumsum().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Groupby Practice Tasks - Baseball Data\n",
    "\n",
    "1. Import the data from this link http://bit.ly/144sh7t (hint: use read_csv) Call it `baseball`\n",
    "2. Check column types, dataframe shape\n",
    "3. How many rows have missing data? \n",
    "3. Find the proportion of missing values in each column\n",
    "4. Find\n",
    "    - The number of rows in every league\n",
    "    - The count of records per year\n",
    "    - Average, Median experience of players participating in each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "baseball = pd.read_csv(\"http://bit.ly/144sh7t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "baseball.columns.values"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Batting Table\n",
    "playerID       Player ID code\n",
    "yearID         Year\n",
    "stint          player's stint (order of appearances within a season)\n",
    "teamID         Team\n",
    "lgID           League\n",
    "G              Games\n",
    "AB             At Bats\n",
    "R              Runs\n",
    "H              Hits\n",
    "2B             Doubles\n",
    "3B             Triples\n",
    "HR             bbbbHomeruns\n",
    "RBI            Runs Batted In\n",
    "SB             Stolen Bases\n",
    "CS             Caught Stealing\n",
    "BB             Base on Balls\n",
    "SO             Strikeouts\n",
    "IBB            Intentional walks\n",
    "HBP            Hit by pitch\n",
    "SH             Sacrifice hits\n",
    "SF             Sacrifice flies\n",
    "GIDP           Grounded into double plays"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
